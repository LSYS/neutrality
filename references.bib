@article{AEP2015,
abstract = {How do the media affect public support for democratic institutions in a fragile democracy? What role do they play in a dictatorial regime? We study these questions in the context of Germany of the 1920s and 1930s. During the democratic period, when the Weimar government introduced progovernment political news, the growth of Nazi popularity slowed down in areas with access to radio. This effect was reversed during the campaign for the last competitive election as a result of the pro-Nazi radio broadcast following Hitler's appointment as chancellor. During the consolidation of dictatorship, radio propaganda helped the Nazis enroll new party members. After the Nazis established their rule, radio propaganda incited anti-Semitic acts and denunciations of Jews to authorities by ordinary citizens. The effect of anti-Semitic propaganda varied depending on the listeners' predispositions toward the message. Nazi radio was most effective in places where anti-Semitism was historically high and had a negative effect in places with historically low anti-Semitism. JEL Codes: D7, N34, N44.},
annote = {10.1093/qje/qjv030},
author = {Adena, Maja and Enikolopov, Ruben and Petrova, Maria and Santarosa, Veronica and Zhuravskaya, Ekaterina},
doi = {10.1093/qje/qjv030},
file = {::},
issn = {0033-5533},
journal = {The Quarterly Journal of Economics},
number = {4},
pages = {1885--1939},
title = {{Radio and the Rise of The Nazis in Prewar Germany}},
url = {http://dx.doi.org/10.1093/qje/qjv030},
volume = {130},
year = {2015}
}
@article{AET2005,
abstract = {In this paper we measure the effect of Catholic high school attendance on educational attainment and test scores. Because we do not have a good instrumental variable for Catholic school attendance, we develop new estimation methods based on the idea that the amount of selection on the observed explanatory variables in a model provides a guide to the amount of selection on the unobservables. We also propose an informal way to assess selectivity bias based on measuring the ratio of selection on unobservables to selection on observables that would be required if one is to attribute the entire effect of Catholic school attendance to selection bias. We use our methods to estimate the effect of attending a Catholic high school on a variety of outcomes. Our main conclusion is that Catholic high schools substantially increase the probability of graduating from high school and, more tentatively, attending college. We find little evidence of an effect on test scores.},
author = {Altonji, Joseph and Elder, Todd and Taber, Christopher},
doi = {10.1086/426036},
file = {::},
isbn = {00223808, 1537534X},
journal = {Journal of Political Economy},
number = {1},
pages = {151--184},
publisher = {University of Chicago Press},
title = {{Selection on Observed and Unobserved Variables: Assessing the Effectiveness of Catholic Schools}},
url = {http://www.jstor.org.ezlibproxy1.ntu.edu.sg/stable/10.1086/426036},
volume = {113},
year = {2005}
}
@article{Anderson2012,
abstract = {We present an economic model of media bias and media mergers. Media owners have political motives as well as profit motives, and can influence public opinion by withholding information that is pejorative to their political agenda—provided that their agenda is not too far from the political mainstream. This is true even with rational consumers who understand the media owners' biases, because the public do not know how much information the news organizations have and so do not know when news is being withheld. In line with conventional wisdom, this problem can be undone by competition; but competition can be defeated in equilibrium by media mergers that enhance profits at the expense of the public interest. We thus derive a motive for media merger policy that is completely distinct from the motives behind conventional antitrust. While media bias may reduce the profit incentives to merge, media markets nonetheless err by being insufficiently competitive, and the consequences of merger are more severe than in other markets.},
author = {Anderson, Simon P and McLaren, John},
doi = {10.1111/j.1542-4774.2012.01069.x},
file = {::},
issn = {1542-4774},
journal = {Journal of the European Economic Association},
keywords = {D23,L82)},
number = {4},
pages = {831--859},
publisher = {Blackwell Publishing Inc},
title = {{Media Mergers and Media Bias With Rational Consumers}},
volume = {10},
year = {2012}
}
@book{MHE,
  title={Mostly Harmless Econometrics: An Empiricist's Companion},
  author={Angrist, Joshua D. and Pischke, J{\"o}rn-Steffen},
  year={2009},
  publisher={Princeton University Press},
  address={Princeton, NJ},
  isbn={9780691120355},
}

@article{Antweiler2004,
abstract = {Financial press reports claim that Internet stock message boards can move markets. We study the effect of more than 1.5 million messages posted on Yahoo! Finance and Raging Bull about the 45 companies in the Dow Jonbaly2019multies Industrial Average and the Dow Jones Internet Index. Bullishness is measured using computational linguistics methods. Wall Street Journal news stories are used as controls. We find that stock messages help predict market volatility. Their effect on stock returns is statistically significant but economically small. Consistent with Harris and Raviv (1993), disagreement among the posted messages is associated with increased trading volume.},
annote = {Conclusion does the job},
author = {Antweiler, Werner and Frank, Murray Z},
doi = {10.1111/j.1540-6261.2004.00662.x},
file = {::},
issn = {1540-6261},
journal = {The Journal of Finance},
month = {jun},
number = {3},
pages = {1259--1294},
publisher = {Blackwell Publishing, Inc.},
title = {{Is All That Talk Just Noise? The Information Content of Internet Stock Message Boards}},
url = {http://dx.doi.org/10.1111/j.1540-6261.2004.00662.x},
volume = {59},
year = {2004}
}
@misc{BBC2013,
author = {{BBC News}},
title = {{Singapore profile - Media}},
url = {http://www.bbc.com/news/world-asia-15966553},
year = {2013}
}
@article{Bernhardt2008,
abstract = {We develop a model in which profits of media firms depend on their audience ratings, and maximizing profits may involve catering to a partisan audience by suppressing information that the partisan audience does not like hearing. While voters are rational, understand the nature of the news suppression bias and update appropriately, important information is lost through bias and can lead to electoral mistakes. We characterize those conditions that give rise to electoral mistakes, showing that heightened political polarization and asymmetric distributions of voter ideologies make electoral mistakes more likely. Even if the median ideology is a centrist and centrist voters gain access to unbiased news, media bias can generate excessive “cross-over” voting, which, in turn, can lead to the election of the wrong candidate.},
author = {Bernhardt, Dan and Krasa, Stefan and Polborn, Mattias},
doi = {10.1016/j.jpubeco.2008.01.006},
file = {::},
issn = {0047-2727},
journal = {Journal of Public Economics},
keywords = {Democracy,Information aggregation,Media bias,Polarization},
number = {5},
pages = {1092--1104},
title = {{Political Polarization and the Electoral Effects of Media Bias}},
url = {http://www.sciencedirect.com/science/article/pii/S0047272708000236},
volume = {92},
year = {2008}
}
@article{Berry1967,
annote = {doi: 10.1177/107769906704400309},
author = {Berry, Fred C},
doi = {10.1177/107769906704400309},
file = {::},
issn = {0022-5533},
journal = {Journalism Quarterly},
number = {3},
pages = {482--490},
publisher = {SAGE Publications},
title = {{A Study of Accuracy in Local News Stories of Three Dailies}},
url = {https://doi.org/10.1177/107769906704400309},
volume = {44},
year = {1967}
}
@article{Besley2002,
abstract = {The determinants of government responsiveness to its citizens are a key issue in political economy. Here, we develop a model based on the solution of political agency problems. Having a more informed and politically active electorate strengthens incentives for governments to be responsive. This suggests that there is a role for both democratic institutions and mass media in ensuring that the preferences of citizens are reflected in policy. The ideas behind the model are tested on panel data from India. We show that state governments are more responsive to falls in food production and crop flood damage via public food distribution and calamity relief expenditure where newspaper circulation is higher and electoral accountability greater.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Besley, T. and Burgess, R.},
doi = {10.1162/003355302320935061},
eprint = {arXiv:1011.1669v3},
file = {::},
isbn = {00335533},
issn = {0033-5533},
journal = {The Quarterly Journal of Economics},
number = {4},
pages = {1415--1451},
pmid = {25246403},
title = {{The Political Economy of Government Responsiveness: Theory and Evidence from India}},
url = {https://academic.oup.com/qje/article-lookup/doi/10.1162/003355302320935061},
volume = {117},
year = {2002}
}
@article{Besley2006,
author = {Besley, Timothy and Prat, Andrea},
doi = {10.1257/aer.96.3.720},
file = {::},
journal = {American Economic Review},
number = {3},
pages = {720--736},
title = {{Handcuffs for the Grabbing Hand? Media Capture and Government Accountability}},
url = {http://www.aeaweb.org/articles?id=10.1257/aer.96.3.720},
volume = {96},
year = {2006}
}
@article{Blei2012,
author = {Blei, David},
doi = {10.1145/2133806.2133826},
file = {::},
journal = {Communications of the ACM},
number = {4},
title = {{Probabilistic topic models}},
volume = {55},
year = {2012}
}
@article{Blei2003,
abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Blei, David and Ng, Andrew Y and Jordan, Michael I.},
doi = {10.1162/jmlr.2003.3.4-5.993},
eprint = {1111.6189v1},
file = {::},
isbn = {9781577352815},
issn = {15324435},
journal = {Journal of Machine Learning Research},
pages = {993--1022},
pmid = {21362469},
title = {{Latent Dirichlet Allocation}},
volume = {3},
year = {2003}
}
@article{Boas2011,
abstract = {Direct influence over communication media is a potent resource during electoral campaigns, and politicians have an incentive to gain control of the airwaves to advance their careers. In this article, we use data on community radio license applications in Brazil to identify both the causal effect of incumbency on politicians' ability to control the media and the causal effect of media control on their future electoral prospects. Using a regression discontinuity design, we compare city council candidates who barely won or barely lost an election, showing that incumbency more than doubles the probability of an application's approval by the Ministry of Communications. Next, using genetic matching, we compare candidates who acquired community radio licenses before an election to similar politicians who did not, showing that a radio station substantially increases one's vote share and probability of victory. These findings demonstrate that media control helps entrench local political power in Brazil.},
author = {Boas, Taylor C and Hidalgo, F Daniel},
doi = {10.1111/j.1540-5907.2011.00532.x},
file = {::},
issn = {1540-5907},
journal = {American Journal of Political Science},
number = {4},
pages = {869--885},
publisher = {Blackwell Publishing Inc},
title = {{Controlling the Airwaves: Incumbency Advantage and Community Radio in Brazil}},
url = {http://dx.doi.org/10.1111/j.1540-5907.2011.00532.x},
volume = {55},
year = {2011}
}
@article{Bossetta2018,
abstract = {State-sponsored “bad actors” increasingly weaponize social media platforms to launch cyberattacks and disinformation campaigns during elections. Social media companies, due to their rapid growth and scale, struggle to prevent the weaponization of their platforms. This study conducts an automated spear phishing and disinformation campaign on Twitter ahead of the 2018 United States midterm elections. A fake news bot account — the @DCNewsReport — was created and programmed to automatically send customized tweets with a “breaking news” link to 138 Twitter users, before being restricted by Twitter.Overall, one in five users clicked the link, which could have potentially led to the downloading of ransomware or the theft of private information. However, the link in this experiment was non-malicious and redirected users to a Google Forms survey. In predicting users' likelihood to click the link on Twitter, no statistically significant differences were observed between right-wing and left-wing partisans, or between Web users and mobile users. The findings signal that politically expressive Americans on Twitter, regardless of their party preferences or the devices they use to access the platform, are at risk of being spear phished on social media.},
author = {Bossetta, Michael},
doi = {10.5210/fm.v23i12.9540},
journal = {First Monday},
number = {12},
pages = {1--23},
title = {{A simulated cyberattack on Twitter: Assessing partisan vulnerability to spear phishing and disinformation ahead of the 2018 U.S. midterm elections}},
volume = {23},
year = {2018}
}
@article{Bouma2009,
abstract = {In this paper, we discuss the related information theoreti- cal association measures of mutual information and pointwise mutual information, in the context of collocation extraction. We introduce nor- malized variants of these measures in order to make them more easily interpretable and at the same time less sensitive to occurrence frequency. We also provide a small empirical study to give more insight into the be- haviour of these new measures in a collocation extraction setup. 1},
author = {Bouma, Gerlof},
file = {::},
journal = {Proceedings of German Society for Computational Linguistics (GSCL 2009)},
pages = {31--40},
title = {{Normalized ( Pointwise ) Mutual Information in Collocation Extraction}},
year = {2009}
}
@article{Breiman2001,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
author = {Breiman, Leo},
doi = {10.1023/A:1010933404324},
file = {::},
issn = {1573-0565},
journal = {Machine Learning},
number = {1},
pages = {5--32},
title = {{Random Forests}},
url = {https://doi.org/10.1023/A:1010933404324},
volume = {45},
year = {2001}
}
@article{Brunetti2003,
abstract = {This paper tests the proposition that a free press may be a powerful control on corruption. We find evidence of a significant relationship between more press freedom and less corruption in a large cross-section of countries. This result is robust to specification and sample and the relationship is not sensitive to the choice of a particular measure of corruption or of press freedom. Furthermore we present evidence which suggests that the direction of causation runs from higher press freedom to lower corruption.},
annote = {Accession Number: S0047272701001864; Author: Brunetti, Aymo (a); Author: Weder, Beatrice (b, ∗); Affiliation: State Secretariat for Economic Affairs, Bern, Basel, Switzerland; Affiliation: University of Mainz, Mainz, Germany; Number of Pages: 24; Language: English;},
author = {Brunetti, Aymo and Weder, Beatrice},
doi = {10.1016/S0047-2727(01)00186-4},
file = {::},
issn = {0047-2727},
journal = {Journal of Public Economics},
pages = {1801--1824},
publisher = {Elsevier B.V.},
title = {{A Free Press is Bad News for Corruption}},
url = {http://10.0.3.248/S0047-2727(01)00186-4 http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=edselp{\&}AN=S0047272701001864{\&}site=eds-live{\&}scope=site},
volume = {87},
year = {2003}
}
@article{Caruana2006,
abstract = {A number of supervised learning methods have been introduced in the$\backslash$nlast decade. Unfortunately, the last comprehensive empirical evaluation$\backslash$nof supervised learning was the Statlog Project in the early 90's.$\backslash$nWe present a large-scale empirical comparison between ten supervised$\backslash$nlearning methods: SVMs, neural nets, logistic regression, naive bayes,$\backslash$nmemory-based learning, random forests, decision trees, bagged trees,$\backslash$nboosted trees, and boosted stumps. We also examine the effect that$\backslash$ncalibrating the models via Platt Scaling and Isotonic Regression$\backslash$nhas on their performance. An important aspect of our study is the$\backslash$nuse of a variety of performance criteria to evaluate the learning$\backslash$nmethods.},
author = {Caruana, Rich and Niculescu-Mizil, Alexandru},
doi = {10.1145/1143844.1143865},
file = {::},
isbn = {1-59593-383-2},
issn = {1595933832},
journal = {Proceedings of the 23th International Conference on Machine Learning},
pages = {161--168},
pmid = {1000253691},
title = {{An empirical comparison of supervised learning algorithms}},
url = {http://doi.acm.org/10.1145/1143844.1143865},
year = {2006}
}

@inproceedings{Chang2009,
author = {Chang, Jonathan and Boyd-Graber, Jordan and Gerrish, Sean and Wang, Chong and Blei, David M.},
title = {Reading tea leaves: how humans interpret topic models},
year = {2009},
isbn = {9781615679119},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 22nd International Conference on Neural Information Processing Systems},
pages = {288-296},
numpages = {9},
location = {Vancouver, British Columbia, Canada},
series = {NIPS'09},
doi = {10.5555/2984093.2984126},
}

@article{SMOTE2002,
abstract = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally rep-resented. Often real-world data sets are predominately composed of " normal " examples with only a small percentage of " abnormal " or " interesting " examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (nor-mal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.},
archivePrefix = {arXiv},
arxivId = {1106.1813},
author = {Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip},
doi = {10.1613/jair.953},
eprint = {1106.1813},
file = {::},
isbn = {013805326X},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {321--357},
pmid = {18190633},
title = {{SMOTE: Synthetic minority over-sampling technique}},
volume = {16},
year = {2002}
}
@article{Chia2007,
abstract = {This study examines the hostile media effect in relation to partisans' perception of the slant of news coverage in a highly regulated press environment—Singapore. We found that partisans in Singapore perceived unbiased news to be in favor of the other side, while the nonpartisans perceived the same news to be neutral. Our findings show that hostile media effects can persist in a restricted press environment where people are aware of the government's control of media coverage. We also found that partisans' awareness of the government's control of media information contributed to their perception of the article slant as well.},
annote = {10.1093/ijpor/edm011},
author = {Chia, Stella C and Yong, Shing Yew Joel and Wong, Zi Wen Diana and Koh, Wei Ling},
file = {::},
issn = {0954-2892},
journal = {International Journal of Public Opinion Research},
month = {oct},
number = {3},
pages = {313--330},
title = {{Personal Bias or Government Bias? Testing the Hostile Media Effect in a Regulated Press System}},
url = {http://dx.doi.org/10.1093/ijpor/edm011},
volume = {19},
year = {2007}
}
@article{Chiang2011,
abstract = {This paper investigates the relationship between media bias and the influence of the media on voting in the context of newspaper endorsements. We first develop a simple econometric model in which voters choose candidates under uncertainty and rely on endorsements from better informed sources. Newspapers are potentially biased in favour of one of the candidates and voters thus rationally account for the credibility of any endorsements. Our primary empirical finding is that endorsements are influential in the sense that voters are more likely to support the recommended candidate after publication of the endorsement. The degree of this influence, however, depends upon the credibility of the endorsement. In this way, endorsements for the Democratic candidate from left-leaning newspapers are less influential than are endorsements from neutral or right-leaning newspapers and likewise for endorsements for the Republican. We also find that endorsements are more influential among moderate voters and those more likely to be exposed to the endorsement. In sum, these findings suggest that voters do rely on the media for information during campaigns but that the extent of this reliance depends upon the degree and direction of any bias.},
annote = {10.1093/restud/rdq037},
author = {Chiang, Chun-Fang and Knight, Brian},
doi = {10.1093/restud/rdq037},
file = {::},
issn = {0034-6527},
journal = {The Review of Economic Studies},
number = {3},
pages = {795--820},
title = {{Media Bias and Influence: Evidence from Newspaper Endorsements}},
url = {10.1093/restud/rdq037},
volume = {78},
year = {2011}
}
@article{Chotlos1944,
abstract = {The present investigation is concerned with the relation of certain language variables to the length of sample from which they are derived and certain psychologically pertinent factors. The object of this study may be oriented around the analysis of the number of different words (D) as a function of the total number of words (N). As part of a remedial education survey, sponsored by the Iowa Child Welfare Research Station and financed by the Federal Work Projects Administration, approximately 1,000 public school children with schizophrenia wrote manuscripts of 3,000 words each under conditions to be specified below. It should be realized that the recording, tabulating, and counting operations in this study were unusually extensive. Three-thousand-word written language samples were obtained from 108 Iowa school children who had been selected to fill the cells of a factorial design which consisted of three levels each of I.Q., C.A., and locality (city, town, rural) as well as two equal groups of boys and girls. The subjects were asked to write about whatever they wanted to write about and in a free-writing situation for a short time each day until they had reached their quota of 3,000 words. Each language sample was edited and the words tabulated according to a set of predetermined rules. From these tabulations, 20 language measures were obtained for each sample, and individual cumulative type-frequency curves were computed for a selected group of subjects. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
address = {US},
annote = {Accession Number: 2011-16010-004. Other Journal Title: Psychological Monographs: General and Applied; The Psychological Monographs; The Psychological Review: Monograph Supplements. Partial author list: First Author {\&} Affiliation: Chotlos, John W.; University of Iowa, Iowa City, IA, US. Other Publishers: Macmillan {\&} Company; Psychological Review Company; The Macmillan Company; The Review Publishing Company. Release Date: 20111003. Publication Type: Journal (0100), Peer Reviewed Journal (0110). Format Covered: Electronic. Document Type: Journal Article. Language: English. Major Descriptor: Childhood Development; Schizophrenia; Written Language. Minor Descriptor: Patients. Classification: Schizophrenia {\&} Psychotic States (3213). Population: Human (10); Male (30); Female (40). Location: US. Age Group: Childhood (birth-12 yrs) (100); School Age (6-12 yrs) (180); Adolescence (13-17 yrs) (200). Tests {\&} Measures: Otis Quick-Scoring Mental Ability Test; Ohio State Psychological Test; Nelson-Denny Reading Test. Methodology: Empirical Study; Quantitative Study. References Available: Y. Page Count: 37. Issue Publication Date: 1944.},
author = {Chotlos, John W},
doi = {10.1037/h0093511},
file = {::;::},
issn = {0096-9753},
journal = {Psychological Monographs},
keywords = {Childhood Development,Patients,Schizophrenia,Written Language,childhood development,schizophrenic patients,written language},
number = {2},
pages = {75--111},
publisher = {American Psychological Association},
title = {{IV. A Statistical and Comparative Analysis of Individual Written Language Samples}},
url = {http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=psyh{\&}AN=2011-16010-004{\&}site=eds-live{\&}scope=site},
volume = {56},
year = {1944}
}
@article{Corneo2006,
abstract = {Since objective news coverage is vital to democracy, captured media can seriously distort collective decisions. The current paper develops a voting model where citizens are uncertain about the welfare effects induced by alternative policy options and derive information about those effects from the mass media. The media might however secretly collude with interest groups in order to influence the public opinion. In the case of voting over the level of a productivity-enhancing public bad, it is shown that an increase in the concentration of firm ownership makes the occurrence of media bias more likely. Although media bias is not always welfare worsening, conditions for it to raise welfare are restrictive.},
author = {Corneo, Giacomo},
doi = {10.1016/j.jpubeco.2005.08.002},
file = {::},
issn = {0047-2727},
journal = {Journal of Public Economics},
keywords = {Mass media,Public bads,Voting,Wealth inequality},
number = {1},
pages = {37--58},
title = {{Media Capture in a Democracy: The Role of Wealth Concentration}},
url = {http://www.sciencedirect.com/science/article/pii/S0047272705001210},
volume = {90},
year = {2006}
}
@article{Covington2010,
abstract = {Abstract Type?token ratio (TTR), or vocabulary size divided by text length (V/N), is a time-honoured but unsatisfactory measure of lexical diversity. The problem is that the TTR of a text sample is affected by its length. We present an algorithm for rapidly computing TTR through a moving window that is independent of text length, and we demonstrate that this measurement can detect changes within a text as well as differences between texts.},
annote = {doi: 10.1080/09296171003643098},
author = {Covington, Michael A and McFall, Joe D},
doi = {10.1080/09296171003643098},
file = {::},
issn = {0929-6174},
journal = {Journal of Quantitative Linguistics},
month = {may},
number = {2},
pages = {94--100},
publisher = {Routledge},
title = {{Cutting the Gordian Knot: The Moving-Average Type–Token Ratio (MATTR)}},
url = {https://doi.org/10.1080/09296171003643098},
volume = {17},
year = {2010}
}
@article{DAlessio2003,
abstract = {Perceptions of media bias were explored by manipulating expectations of bias and news topic. Readers were more likely to designate material opposing their own viewpoints as biased. Perception of bias was topic-dependent and statements most often viewed as biased were quotations, rather than other types of statements.},
annote = {doi: 10.1177/107769900308000204},
author = {D'Alessio, Dave},
doi = {10.1177/107769900308000204},
file = {::},
issn = {1077-6990},
journal = {Journalism {\&} Mass Communication Quarterly},
number = {2},
pages = {282--294},
publisher = {SAGE Publications Inc},
title = {{An Experimental Examination of Readers' Perceptions of Media Bias}},
url = {https://doi.org/10.1177/107769900308000204},
volume = {80},
year = {2003}
}
@article{DellaVigna2007,
abstract = {Does media bias affect voting? We analyze the entry of Fox News in cable markets and its impact on voting. Between October 1996 and November 2000, the conservative Fox News Channel was introduced in the cable programming of 20 percent of U. S. towns. Fox News availability in 2000 appears to be largely idiosyncratic, conditional on a set of controls. Using a data set of voting data for 9,256 towns, we investigate if Republicans gained vote share in towns where Fox News entered the cable market by the year 2000. We find a significant effect of the introduction of Fox News on the vote share in Presidential elections between 1996 and 2000. Republicans gained 0.4 to 0.7 percentage points in the towns that broadcast Fox News. Fox News also affected voter turnout and the Republican vote share in the Senate. Our estimates imply that Fox News convinced 3 to 28 percent of its viewers to vote Republican, depending on the audience measure. The Fox News effect could be a temporary learning effect for rational voters, or a permanent effect for nonrational voters subject to persuasion. [ABSTRACT FROM AUTHOR] Copyright of Quarterly Journal of Economics is the property of Oxford University Press / USA and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {DellaVigna, Stefano 1,2; Kaplan, Ethan 3,4; Affiliations: 1: UC BERKELEY; 2: NBER; 3: IIES; 4: STOCKHOLM UNIVERSITY; Issue Info: Aug2007, Vol. 122 Issue 3, p1187; Thesaurus Term: JOURNALISM; Subject Term: PRESS influence; Subject Term: VOTING -- Social aspects; Subject Term: SOCIAL aspects; Subject Term: PRESIDENTS -- United States -- Election; Subject Term: VOTERS ; Company/Entity: FOX News ; Company/Entity: REPUBLICAN Party (U.S. : 1854- ) -- Elections; Number of Pages: 48p; Illustrations: 11 Charts, 1 Map; Document Type: Article; Full Text Word Count: 18460},
author = {DellaVigna, Stefano and Kaplan, Ethan},
doi = {10.1162/qjec.122.3.1187},
file = {::;::},
isbn = {00335533},
journal = {Quarterly Journal of Economics},
keywords = {FOX News,JOURNALISM,PRESIDENTS -- United States -- Election,PRESS influence,REPUBLICAN Party (U.S. : 1854- ) -- Elections,SOCIAL aspects,VOTERS,VOTING -- Social aspects},
number = {3},
pages = {1187--1234},
pmid = {25953408},
publisher = {Oxford University Press / USA},
title = {{The Fox News Effect: Media Bias and Voting}},
url = {http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=buh{\&}AN=25953408{\&}site=eds-live{\&}scope=site},
volume = {122},
year = {2007}
}
@article{Druckman2001,
abstract = {This paper examines Tversky and Kahneman's well-known Asian disease framing problem (A. Tversky, D. Kahneman, Science 211 (1981) 453–458). I describe an experiment where respondents received a version of the disease problem using a survival format, a mortality format, or both formats. The results from the survival and mortality formats replicate Tversky and Kahneman's original experiment both in terms of statistical significance and, in contrast to some other studies, in terms of magnitude. I then argue that the “both format” condition constitutes an important and previously unused baseline for evaluating the strength of framing effects. This standard of comparison provides a way to evaluate the impact of a frame on unadulterated preferences – that is, preferences unaffected by a particular frame. The implications for future framing effect experiments are discussed.},
author = {Druckman, James N},
doi = {10.1016/S0167-4870(00)00032-5},
file = {::},
issn = {0167-4870},
journal = {Journal of Economic Psychology},
keywords = {Framing effect},
number = {1},
pages = {91--101},
title = {{Evaluating Framing Effects}},
volume = {22},
year = {2001}
}
@article{Durante2012,
abstract = {This paper examines whether and how viewers respond to changes in partisan bias in media news. We use data from Italy, where the main private television network is owned by Silvio Berlusconi, the leader of the center-right coalition, and the public television corporation is largely controlled by the ruling coalition. We first document that after the 2001 national elections, when the control of the government moved from the center-left to the center-right, news content on public television shifted to the right. Using individual survey data, we find robust evidence that viewers responded to these changes by modifying their choice of favorite news programs. On the one hand, right-leaning viewers increased their propensity to watch public channels which, even after the change, remained to the left of private channels. On the other hand, left-wing viewers reacted by switching from the main public channel to another public channel that was controlled by the left during both periods. We show that this behavioral response, which tended to shift ideological exposure to the left, significantly, though only partially, offset the movement of public news content to the right. [ABSTRACT FROM AUTHOR]},
annote = {Accession Number: 75050954; Durante, Ruben 1; Knight, Brian 2; Affiliations: 1: Sciences Po; 2: Brown University; Issue Info: May2012, Vol. 10 Issue 3, p451; Thesaurus Term: PUBLIC television; Thesaurus Term: MASS media; Thesaurus Term: TELEVISION programs; Subject Term: BEHAVIORAL assessment; Subject Term: GUERRILLAS; Subject: ITALY; Author-Supplied Keyword: D7; NAICS/Industry Codes: 512110 Motion Picture and Video Production; Number of Pages: 31p; Document Type: Article},
author = {Durante, Ruben and Knight, Brian},
doi = {10.0.4.87/j.1542-4774.2011.01060.x},
file = {::},
issn = {15424766},
journal = {Journal of the European Economic Association},
keywords = {BEHAVIORAL assessment,D7,GUERRILLAS,ITALY,MASS media,PUBLIC television,TELEVISION programs},
number = {3},
pages = {451--481},
publisher = {Wiley-Blackwell},
title = {{Partisan Control, Media Bias, and Viewer Responses: Evidence from Berlusconi's Italy}},
url = {http://10.0.4.87/j.1542-4774.2011.01060.x http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=buh{\&}AN=75050954{\&}site=eds-live{\&}scope=site},
volume = {10},
year = {2012}
}
@article{Eisensee2007,
abstract = {This paper studies the influence of mass media on U. S. government response to approximately 5,000 natural disasters occurring between 1968 and 2002. These disasters took nearly 63,000 lives and affected 125 million people per year. We show that U. S. relief depends on whether the disaster occurs at the same time as other newsworthy events, such as the Olympic Games, which are obviously unrelated to need. We argue that the only plausible explanation of this is that relief decisions are driven by news coverage of disasters and that the other newsworthy material crowds out this news coverage.},
annote = {10.1162/qjec.122.2.693},
author = {Eisensee, Thomas and Str{\"{o}}mberg, David},
doi = {10.1162/qjec.122.2.693},
file = {::},
issn = {0033-5533},
journal = {The Quarterly Journal of Economics},
number = {2},
pages = {693--728},
title = {{News Droughts, News Floods, and U. S. Disaster Relief}},
url = {http://dx.doi.org/10.1162/qjec.122.2.693},
volume = {122},
year = {2007}
}
@article{Enikolopov2011,
abstract = {This paper compares electoral outcomes of 1999 parliamentary elections in Russia among geographical areas with differential access to the only national TV channel independent from the government. It was available to three-quarters of Russia's population and its signal availability was idiosyncratic, conditional on observables. Independent TV decreased aggregate vote for the government party by 8.9 percentage points, increased the combined vote for major opposition parties by 6.3 percentage points, and decreased turnout by 3.8 percentage points. The probability of voting for opposition parties increased for individuals who watched independent TV even controlling for voting intentions measured one month before elections.},
author = {Enikolopov, Ruben and Petrova, Maria and Zhuravskaya, Ekaterina},
doi = {10.1257/aer.101.7.3253},
file = {::},
isbn = {00028282},
issn = {00028282},
journal = {American Economic Review},
number = {7},
pages = {3253--3285},
pmid = {9212281121},
title = {{Media and Political Persuasion: Evidence from Russia}},
volume = {101},
year = {2011}
}
@article{Ferraz2008,
abstract = {This paper uses publicly released audit reports to study the effects of disclosing information about corruption practices on electoral accountability. In 2003, as part of an anticorruption program, Brazil's federal government began to select municipalities at random to audit their expenditures of federally transferred funds. The findings of these audits were then made publicly available and disseminated to media sources. Using a data set on corruption constructed from the audit reports, we compare the electoral outcomes of municipalities audited before versus after the 2004 elections, with the same levels of reported corruption. We show that the release of the audit outcomes had a significant impact on incumbents' electoral performance, and that these effects were more pronounced in municipalities where local radio was present to divulge the information. Our findings highlight the value of having a more informed electorate and the role played by local media in enhancing political selection.},
annote = {10.1162/qjec.2008.123.2.703},
author = {Ferraz, Claudio and Finan, Frederico},
doi = {10.1162/qjec.2008.123.2.703},
file = {::},
issn = {0033-5533},
journal = {The Quarterly Journal of Economics},
number = {2},
pages = {703--745},
title = {{Exposing Corrupt Politicians: The Effects of Brazil's Publicly Released Audits on Electoral Outcomes}},
url = {http://dx.doi.org/10.1162/qjec.2008.123.2.703},
volume = {123},
year = {2008}
}
@misc{freedomhouse,
author = {{Freedom House}},
title = {{Freedom of the Press 2017}},
url = {https://freedomhouse.org/report/freedom-press/freedom-press-2017},
urldate = {2017-05-29},
year = {2017}
}
@article{Gentzkow2006a,
abstract = {I use variation across markets in the timing of television's introduction to identify its impact on voter turnout. The estimated effect is significantly negative, accounting for between a quarter and a half of the total decline in turnout since the 1950s. I argue that substitution away from other media with more political coverage provides a plausible mechanism linking television to voting. As evidence for this, I show that the entry of television in a market coincided with sharp drops in consumption of newspapers and radio, and in political knowledge as measured by election surveys. I also show that both the information and turnout effects were largest in off-year congressional elections, which receive extensive coverage in newspapers but little or no coverage on television.},
annote = {The Quarterly Journal of Economics
Item Citation: The Quarterly Journal of Economics, 8/1/2006, Vol. 121, Issue 3, p. 931-972
Accession Number: edsjsr.25098813; Publication Type: Article; Source: The Quarterly Journal of Economics; Language: English; Publication Date: 20060801; Rights: Copyright 2006 The President and Fellows of Harvard College and the Massachusetts Institute of Technology; Imprint: MIT Press},
author = {Gentzkow, Matthew},
doi = {10.1162/qjec.121.3.931},
file = {::},
isbn = {00335533 15314650},
journal = {The Quarterly Journal of Economics},
number = {3},
volume = {121},
pages = {931},
publisher = {MIT Press},
title = {{Television and Voter Turnout}},
url = {http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=edsjsr{\&}AN=edsjsr.25098813{\&}site=eds-live{\&}scope=site},
year = {2006}
}
@article{GentzkowShapiro2006,
abstract = {A Bayesian consumer who is uncertain about the quality of an information source will infer that the source is of higher quality when its reports conform to the consumer's prior expectations. We use this fact to build a model of media bias in which firms slant their reports toward the prior beliefs of their customers in order to build a reputation for quality. Bias emerges in our model even though it can make all market participants worse off. The model predicts that bias will be less severe when consumers receive independent evidence on the true state of the world and that competition between independently owned news outlets can reduce bias. We present a variety of empirical evidence consistent with these predictions.},
annote = {Keywords: Media; Publication Type: Journal Article; Update Code: 200608; Copyright: Copyright of Journal of Political Economy is the property of University of Chicago Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use.},
author = {Gentzkow, Matthew and Shapiro, Jesse M},
doi = {10.1086/499414},
file = {::},
isbn = {00223808},
journal = {Journal of Political Economy},
keywords = {Entertainment,Media L82},
number = {2},
pages = {280--316},
title = {{Media Bias and Reputation}},
url = {http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=eoh{\&}AN=0859377{\&}site=eds-live{\&}scope=site http://www.jstor.org/action/showPublication?journalCode=jpoliecon},
volume = {114},
year = {2006}
}
@article{GentzkowShapiro2010,
abstract = {We construct a new index of media slant that measures the similarity of a news outlet's language to that of a congressional Republican or Democrat. We estimate a model of newspaper demand that incorporates slant explicitly, estimate the slant that would be chosen if newspapers independently maximized their own profits, and compare these profit-maximizing points with firms' actual choices. We find that readers have an economically significant preference for like-minded news. Firms respond strongly to consumer preferences, which account for roughly 20 percent of the variation in measured slant in our sample. By contrast, the identity of a newspaper's owner explains far less of the variation in slant.},
author = {Gentzkow, Matthew and Shapiro, Jesse M},
doi = {10.3982/ECTA7195},
file = {::;::},
issn = {1468-0262},
journal = {Econometrica},
keywords = {Bias,media ownership,text categorization},
number = {1},
pages = {35--71},
publisher = {Blackwell Publishing Ltd},
title = {{What Drives Media Slant? Evidence From U.S. Daily Newspapers}},
url = {http://dx.doi.org/10.3982/ECTA7195},
volume = {78},
year = {2010}
}
@book{George2012,
annote = {Accession Number: ntu.1096358; Other Notes: Includes bibliographical references and index.; Publication Type: Book; Physical Description: xiii, 272 p. ; 23 cm.; Language: English; OCLC: ocn760269057},
author = {George, Cherian},
isbn = {9789971695941},
keywords = {Freedom of the press -- Singapore,Government and the press -- Singapore,Journalism -- Political aspects -- Singapore,Press and politics -- Singapore},
publisher = {Singapore : NUS Press, c2012.},
title = {{Freedom From the Press: Journalism and State Power in Singapore.}},
address = {Singapore},
year = {2012}
}
@article{Gerber2011 ,
abstract = {We report the results of the first large-scale experiment involving paid political advertising. During the opening months of a 2006 gubernatorial campaign, approximately {\$}2 million of television and radio advertising on behalf of the incumbent candidate was deployed experimentally. In each experimental media market, the launch date and volume of television advertising were randomly assigned. In order to gauge movement in public opinion, a tracking poll conducted brief telephone interviews with approximately 1,000 registered voters each day and a brief follow-up one month after the conclusion of the television campaign. Results indicate that televised ads have strong but short-lived effects on voting preferences. The ephemeral nature of these effects is more consistent with psychological models of priming than with models of on-line processing.},
author = {Gerber, Alan S and Gimpel, James G and Green, Donald P and Shaw, Daron R},
doi = {10.1017/S000305541000047X},
edition = {2011/03/09},
file = {::},
issn = {0003-0554},
journal = {American Political Science Review},
number = {1},
pages = {135--150},
publisher = {Cambridge University Press},
title = {{How Large and Long-lasting Are the Persuasive Effects of Televised Campaign Ads? Results from a Randomized Field Experiment}},
url = {https://www.cambridge.org/core/article/how-large-and-longlasting-are-the-persuasive-effects-of-televised-campaign-ads-results-from-a-randomized-field-experiment/DA29FE8A5581C772006A1DEBB21CFC4C},
volume = {105},
year = {2011}
}
@article{Gibson1993,
abstract = {Respondents presented with news reports containing one-sided direct personal testimony challenging the safety of amusement parks perceived the overall safety of such parks to be less adequate than respondents given the same information in indirect testimony or those presented with no testimony at all. This effect emerged only for print reports, not radio.},
annote = {doi: 10.1177/107769909307000405},
author = {Gibson, Rhonda and Zillmann, Dolf},
doi = {10.1177/107769909307000405},
file = {::},
issn = {0022-5533},
journal = {Journalism Quarterly},
number = {4},
pages = {793--800},
publisher = {SAGE Publications},
title = {{The Impact of Quotation in News Reports on Issue Perception}},
url = {https://doi.org/10.1177/107769909307000405},
volume = {70},
year = {1993}
}
@article{Gilbert,
author = {Gilbert, Eric},
file = {::},
title = {{VADER : A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text}}
}
@inproceedings{Griffiths2004,
address = {Cambridge, MA, USA},
author = {Griffiths, Thomas L and Steyvers, Mark and Blei, David M and Tenenbaum, Joshua B},
booktitle = {Proceedings of the 17th International Conference on Neural Information Processing Systems},
file = {::},
pages = {537--544},
publisher = {MIT Press},
series = {NIPS'04},
title = {{Integrating Topics and Syntax}},
url = {http://dl.acm.org/citation.cfm?id=2976040.2976108},
year = {2004}
}
@article{Groeling1998,
abstract = {In recent years presidential charges of maltreatment by the press have become commonplace Various scholarly research into political communication appears to confirm the validity of these charges. However, a number of issues prevent one from inferring bias from the high levels of unfavorable presidential news these studies report. The research reported here is designed to overcome these problems and allow us to test the bias hypothesis more conclusively. Applying this design to the three networks' evening news programs during the years 1990 through 1995, we find qualified support for the bias hypothesis but even more compelling evidence that changes in presidential approval, whether favorable or unfavorable, drive news coverage of the president's public support. We also find surprising differences in the networks' routines and patterns of coverage that call into question the common assumption of homogenous network behavior.},
annote = {doi: 10.2307/2647731},
author = {Groeling, Tim and Kernell, Samuel},
doi = {10.2307/2647731},
file = {::},
issn = {0022-3816},
journal = {The Journal of Politics},
number = {4},
pages = {1063--1087},
publisher = {The University of Chicago Press},
title = {{Is Network News Coverage of the President Biased?}},
url = {https://doi.org/10.2307/2647731},
volume = {60},
year = {1998}
}
@article{GrosecloseMilyo2005,
abstract = {We measure media bias by estimating ideological scores for several major media outlets. To compute this, we count the times that a particular media outlet cites various think tanks and policy groups, and then compare this with the times that members of Congress cite the same groups. Our results show a strong liberal bias: all of the news outlets we examine, except Fox News' Special Report and the Washington Times, received scores to the left of the average member of Congress. Consistent with claims made by conservative critics, CBS Evening News and the New York Times received scores far to the left of center. The most centrist media outlets were PBS NewsHour, CNN's Newsnight, and ABC's Good Morning America; among print outlets, USA Today was closest to the center. All of our findings refer strictly to news content; that is, we exclude editorials, letters, and the like. [ABSTRACT FROM AUTHOR] Copyright of Quarterly Journal of Economics is the property of Oxford University Press / USA and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Groseclose, Tim 1; Milyo, Jeffrey 2; Affiliations: 1: Department of Political Science, University of California, Los Angeles; 2: Department of Economics and Truman School of Public Affairs, University of Missouri; Issue Info: Nov2005, Vol. 120 Issue 4, p1191; Thesaurus Term: MASS media; Thesaurus Term: COMMUNICATION; Thesaurus Term: JOURNALISM; Subject Term: PREJUDICES; Subject Term: CONSERVATIVES; Subject Term: POLITICAL participation; Subject Term: POLITICAL science; Subject Term: RIGHT {\&} left (Political science) ; Company/Entity: UNITED States. Congress; NAICS/Industry Codes: 921120 Legislative Bodies; Number of Pages: 47p; Illustrations: 1 Diagram, 6 Charts, 1 Graph; Document Type: Article; Full Text Word Count: 20143},
author = {Groseclose, Tim and Milyo, Jeffrey},
doi = {10.1162/003355305775097542},
file = {::;::;::},
isbn = {00335533},
journal = {Quarterly Journal of Economics},
keywords = {COMMUNICATION,CONSERVATIVES,JOURNALISM,MASS media,POLITICAL participation,POLITICAL science,PREJUDICES,RIGHT {\&} left (Political science),UNITED States. Congress},
number = {4},
pages = {1191--1237},
pmid = {19099477},
publisher = {Oxford University Press / USA},
title = {{A Measure of Media Bias}},
volume = {120},
year = {2005}
}
@article{Hetherington1996,
abstract = {In terms of economic voting, voters' perceptions of economic indicators can be more important than the statistics themselves. This distinction is particularly important in understanding George Bush's defeat in 1992. Relentlessly negative reporting on economic performance during the election year negatively affected voters' perceptions of the economy. These altered perceptions influenced voting behavior. Ordinary least squares regression is used to demonstrate the media's impact on economic evaluations. Logistic regression is used to demonstrate the importance of economic evaluations in vote choice. Media consumption and attention to the presidential campaign through the mass media negatively shaped voters' retrospective economic assessments. These assessments were significantly related to vote choice. This suggests an explanation for why George Bush lost reelection despite an economy that had rebounded from recession well in advance of election day.},
author = {Hetherington, Marc J},
doi = {10.2307/2111629},
file = {::},
issn = {00925853, 15405907},
journal = {American Journal of Political Science},
number = {2},
pages = {372--395},
publisher = {[Midwest Political Science Association, Wiley]},
title = {{The Media's Role in Forming Voters' National Economic Evaluations in 1992}},
url = {http://www.jstor.org.ezlibproxy1.ntu.edu.sg/stable/2111629},
volume = {40},
year = {1996}
}
@article{Ho2008,
author = {Ho, Daniel E and Quinn, Kevin M},
doi = {10.1561/100.00008048},
file = {::},
issn = {1554-0626},
journal = {Quarterly Journal of Political Science},
keywords = {Interest groups,Judiciary,Public opinion},
number = {4},
pages = {353--377},
publisher = {Now Publishers},
title = {{Measuring Explicit Political Positions of Media}},
volume = {3},
year = {2008}
}
@inproceedings{Ho1995,
abstract = {Decision trees are attractive classifiers due to their high execution speed. But trees derived with traditional methods often cannot be grown to arbitrary complexity for possible loss of generalization accuracy on unseen data. The limitation on complexity usually means suboptimal accuracy on training data. Following the principles of stochastic modeling, we propose a method to construct tree-based classifiers whose capacity can be arbitrarily expanded for increases in accuracy for both training and unseen data. The essence of the method is to build multiple trees in randomly selected subspaces of the feature space. Trees in, different subspaces generalize their classification in complementary ways, and their combined classification can be monotonically improved. The validity of the method is demonstrated through experiments on the recognition of handwritten digits.},
annote = {Item Citation: Proceedings of 3rd International Conference on Document Analysis and Recognition Document Analysis and Recognition, 1995., Proceedings of the Third International Conference on. 1:278-282 vol.1 1995

Related Material: Proceedings of 3rd International Conference on Document Analysis and Recognition

Document Subtype: IEEE Conference

Conference Location: Montreal, Que., Canada

Date of Current Version: 1995

Conference Start Date: 14 Aug. 1995

Conference End Date: 16 Aug. 1995

AMSID: 598994

Accession Number: edseee.598994; Contributors: Tin Kam Ho; Publication Type: Conference Paper; Source: Proceedings of 3rd International Conference on Document Analysis and Recognition, Document Analysis and Recognition, 1995., Proceedings of the Third International Conference on; Language: English; Publication Date: 19950101; Rights: Copyright 1995, IEEE},
author = {Ho, Tin Kam},
booktitle = {Proceedings of 3rd International Conference on Document Analysis and Recognition, Document Analysis and Recognition, 1995., Proceedings of the Third International Conference on VO - 1},
doi = {10.1109/ICDAR.1995.598994},
isbn = {0-8186-7128-9},
keywords = {Classification tree analysis,Decision trees,Handwriting recognition,Hidden Markov models,Multilayer perceptrons,Optimization methods,Stochastic processes,Testing,Tin,Training data},
pages = {278},
title = {{Random Decision Forests}},
url = {http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=edseee{\&}AN=edseee.598994{\&}site=eds-live{\&}scope=site},
year = {1995}
}
@article{Hotelling1929,
annote = {Accession Number: edsjsr.10.2307.2224214; Publication Type: Academic Journal; Source: The Economic Journal; Language: English; Publication Date: 19290301; Imprint: MacMillan and Co. Limited, 1929.},
author = {Hotelling, Harold},
doi = {10.2307/2224214},
file = {::},
issn = {00130133},
journal = {The Economic Journal},
keywords = {Hotelling},
number = {153},
pages = {41},
publisher = {MacMillan and Co. Limited},
title = {{Stability in Competition}},
url = {http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=edsjsr{\&}AN=edsjsr.10.2307.2224214{\&}site=eds-live{\&}scope=site},
volume = {39},
year = {1929}
}
@book{JurafskyMartin,
annote = {Accession Number: ntu.358128; Other Notes: Includes bibliographical references (p. 851-902) and index.; Publication Type: Book; Physical Description: xxvi, 934 p. ; 25 cm.; Language: English; LCCN: 99087845; OCLC: ocm43324289},
author = {Jurafsky, Dan and Martin, James H},
isbn = {0130950696},
keywords = {Automatic speech recognition,Computational linguistics},
publisher = {Upper Saddle River, N.J. : Prentice Hall, 2000.},
series = {Prentice Hall series in artificial intelligence},
title = {{Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition.}},
url = {http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=cat05206a{\&}AN=ntu.358128{\&}site=eds-live{\&}scope=site},
year = {2000}
}
@article{Larcinese2011,
abstract = {We study the agenda-setting political behavior of a large sample of U.S. newspapers during the 1996–2005 period. Our purpose is to examine the intensity of coverage of economic issues as a function of the underlying economic conditions and the political affiliation of the incumbent president, focusing on unemployment, inflation, the federal budget and the trade deficit. We investigate whether there is any significant correlation between the endorsement policy of newspapers, and the differential coverage of bad/good economic news as a function of the president's political affiliation. We find evidence that newspapers with pro-Democratic endorsement pattern systematically give more coverage to high unemployment when the incumbent president is a Republican than when the president is Democratic, compared to newspapers with pro-Republican endorsement pattern. This result is robust to controlling for the partisanship of readers. We find similar but less robust results for the trade deficit. We also find some evidence that newspapers cater to the partisan tastes of readers in the coverage of the budget deficit. We find no evidence of a partisan bias – or at least of a bias that is correlated with the endorsement or reader partisanship – for stories on inflation.},
author = {Larcinese, Valentino and Puglisi, Riccardo and Snyder, James M},
doi = {10.1016/j.jpubeco.2011.04.006},
file = {::;::},
issn = {0047-2727},
journal = {Journal of Public Economics},
keywords = {Information,Mass media,Media bias,News},
number = {9},
pages = {1178--1189},
title = {{Partisan Bias in Economic News: Evidence on the Agenda-setting Behavior of U.S. Newspapers}},
url = {http://www.sciencedirect.com/science/article/pii/S0047272711000715},
volume = {95},
year = {2011}
}
@article{Larreguy2014,
abstract = {We estimate the effect of local media outlets on political accountability in Mexico, focusing on malfeasance by municipal mayors. We study federal grants earmarked for infrastructure projects targeting the poor, and leverage two sources of plausibly exogenous variation. First, we exploit variation in the timing of the release of municipal audit reports. Second, and moving beyond existing studies, we exploit variation in media exposure at the electoral precinct level. In particular, we compare neighboring precincts on the boundaries of media stations' coverage areas to isolate the effects of an additional media station. We find that voters punish the party of malfeasant mayors, but only in electoral precincts covered by local media stations (which emit from within the precinct's municipality). An additional local radio or television station reduces the vote share of an incumbent political party revealed to be corrupt by 1 percentage point, and reduces the vote share of an incumbent political party revealed to have diverted funds to projects not benefiting the poor by around 2 percentage points. We also show that these electoral sanctions persist: at the next election, the vote share of the current incumbent's party continues to be reduced by a similar magnitude. The electoral costs of diverting resources away from the poor are especially large for the populist Institutional Revolutionary Party (PRI) party. However, we find no effect of media stations based in other municipalities.},
author = {Larreguy, Horacio A and Marshall, John and {Snyder Jr.}, James M},
doi = {10.3386/w20697},
file = {::},
journal = {National Bureau of Economic Research Working Paper Series},
keywords = {Development Economics, Public Economics, Political},
pages = {1--57},
title = {{Revealing Malfeasance: How Local Media Facilitates Electoral Sanctioning of Mayors in Mexico}},
url = {http://www.nber.org/papers/w20697{\%}5Cnhttp://www.nber.org/papers/w20697.pdf},
volume = {No. 20697},
year = {2014}
}
@article{Lau2014,
abstract = {Topic models based on latent Dirichlet allocation and related methods are used in a range of user-focused tasks including document navigation and trend analysis, but evaluation of the intrinsic quality of the topic model and topics remains an open research area. In this work, we explore the two tasks of automatic evaluation of single topics and automatic evaluation of whole topic models, and provide recommendations on the best strategy for performing the two tasks, in addition to providing an open-source toolkit for topic and topic model evaluation.},
archivePrefix = {arXiv},
arxivId = {1606.05908},
author = {Lau, Jey Han and Newman, David and Baldwin, Timothy},
eprint = {1606.05908},
file = {::},
isbn = {9781632663962},
journal = {Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2014)},
number = {Eacl},
pages = {530--539},
title = {{Machine Reading Tea Leaves : Automatically Evaluating Topic Coherence and Topic Model Quality}},
url = {http://www.aclweb.org/anthology/E14-1056},
year = {2014}
}
@article{Lehrer1989,
annote = {doi: 10.1177/107769908906600420},
author = {Lehrer, Adrienne},
doi = {10.1177/107769908906600420},
file = {::},
issn = {0022-5533},
journal = {Journalism Quarterly},
number = {4},
pages = {902--941},
publisher = {SAGE Publications},
title = {{Between Quotation Marks}},
url = {https://doi.org/10.1177/107769908906600420},
volume = {66},
year = {1989}
}
@article{imblearn2017,
abstract = {Imbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset frequently encountered in machine learning and pattern recognition. The implemented state-of-the-art methods can be categorized into 4 groups: (i) under-sampling, (ii) over-sampling, (iii) combination of over- and under-sampling, and (iv) ensemble learning methods. The proposed toolbox only depends on numpy, scipy, and scikit-learn and is distributed under MIT license. Furthermore, it is fully compatible with scikit-learn and is part of the scikit-learn-contrib supported project. Documentation, unit tests as well as integration tests are provided to ease usage and contribution. The toolbox is publicly available in GitHub: https://github.com/scikit-learn-contrib/imbalanced-learn.},
archivePrefix = {arXiv},
arxivId = {1609.06570},
author = {Lemaitre, Guillaume and Nogueira, Fernando and Aridas, Christos K.},
doi = {http://www.jmlr.org/papers/volume18/16-365/16-365.pdf},
eprint = {1609.06570},
file = {::},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {ensemble learning,imbalanced dataset,machine learning,over-sampling,python,under-sampling},
pages = {1--5},
title = {{Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning}},
url = {http://arxiv.org/abs/1609.06570},
volume = {18},
year = {2017}
}
@article{Levin1988,
abstract = {Consumers rated several qualitative attributes of ground beef that framed the beef as either “75{\%} lean” or “25{\%} fat.” The consumers' evaluations were more favorable toward the beef labeled “75{\%} lean” than that labeled “25{\%} fat.” More importantly, the magnitude of this information framing effect lessened when consumers actually tasted the meat. We discuss these results in terms of an averaging model, which suggests that a diagnostic product experience dilutes the impact of information framing.},
annote = {10.1086/209174},
author = {Levin, Irwin P and Gaeth, Gary J},
doi = {10.1086/209174},
issn = {0093-5301},
journal = {Journal of Consumer Research},
number = {3},
pages = {374--378},
title = {{How Consumers Are Affected by the Framing of Attribute Information Before and After Consuming the Product}},
url = {http://dx.doi.org/10.1086/209174},
volume = {15},
year = {1988}
}
@article{Levin1998,
abstract = {Accentuate the positive or accentuate the negative? The literature has been mixed as to how the alternative framing of information in positive or negative terms affects judgments and decisions. We argue that this is because different studies have employed different operational definitions of framing and thus have tapped different underlying processes. We develop a typology to distinguish between three different kinds of valence framing effects. First we discuss the standard risky choice framing effect introduced by Tversky and Kahneman (1981) to illustrate how valence affects willingness to take a risk. Then we discuss attribute framing, which affects the evaluation of object or event characteristics, and goal framing, which affects the persuasiveness of a communication. We describe the distinctions, provide a number of examples of each type, and discuss likely theoretical mechanisms underlying each type of framing effect. Our typology helps explain and resolve apparent confusions in the literature, ties together studies with common underlying mechanisms, and serves as a guide to future research and theory development. We conclude that a broader perspective, focused on the cognitive and motivational consequences of valence-based encoding, opens the door to a deeper understanding of the causes and consequences of framing effects.},
author = {Levin, Irwin P and Schneider, Sandra L and Gaeth, Gary J},
doi = {10.1006/obhd.1998.2804},
file = {::},
issn = {0749-5978},
journal = {Organizational Behavior and Human Decision Processes},
number = {2},
pages = {149--188},
title = {{All Frames Are Not Created Equal: A Typology and Critical Analysis of Framing Effects}},
volume = {76},
year = {1998}
}
@article{Lim2015,
abstract = {89},
author = {Lim, Claire S H and Snyder, James M and Str{\"{o}}mberg, David},
doi = {10.1257/app.20140111},
file = {::},
isbn = {1945-7782 1945-7790},
journal = {American Economic Journal: Applied Economics},
number = {4},
pages = {103--135},
title = {{The Judge, the Politician, and the Press: Newspaper Coverage and Criminal Sentencing across Electoral Systems}},
volume = {7},
year = {2015}
}
@article{Loh2014,
abstract = {Fifty years have passed since the publication of the first regression tree algorithm. New techniques have added capabilities that far surpass those of the early methods. Modern classification trees can partition the data with linear splits on subsets of variables and fit nearest neighbor, kernel density, and other models in the partitions. Regression trees can fit almost every kind of traditional statistical model, including least-squares, quantile, logistic, Poisson, and proportional hazards models, as well as models for longitudinal and multiresponse data. Greater availability and affordability of software (much of which is free) have played a significant role in helping the techniques gain acceptance and popularity in the broader scientific community. This article surveys the developments and briefly reviews the key ideas behind some of the major algorithms.},
author = {Loh, Wei-Yin},
doi = {10.1111/insr.12016},
file = {::},
issn = {1751-5823},
journal = {International Statistical Review},
keywords = {Classification trees,machine learning,prediction,regression trees},
month = {dec},
number = {3},
pages = {329--348},
title = {{Fifty Years of Classification and Regression Trees}},
url = {http://dx.doi.org/10.1111/insr.12016},
volume = {82},
year = {2014}
}
@article{Lott2014,
abstract = {This paper develops an econometric technique to test for political bias in news reports that controls for the underlying character of the news reported. Because of the changing availability of the number of newspapers in Nexis/Lexis, two sets of time are examined: from January 1991 to May 2004 and from January 1985 to May 2004. Our results suggest that American newspapers tend to give more positive coverage to the same economic news when Democrats are in the White House than when Republicans are; a similar though smaller effect is found for Democratic control of Congress. Our results reject the claim that “reader diversity is a powerful force toward accuracy.” When all types of news are pooled into a single analysis, our results are significant. However, the results vary greatly depending upon which types of economic data are being reported. When newspapers are examined individually the only support that Republicans appear to obtain is from the president's home state newspapers during his term. This is true for the Houston Chronicle under both Bushes and the Los Angeles Times during the Reagan administration. Contrary to rational expectations, media coverage affects people's perceptions of the economy.},
author = {Lott, John R and Hassett, Kevin A},
doi = {10.1007/s11127-014-0171-5},
file = {::;::},
issn = {1573-7101},
journal = {Public Choice},
number = {1},
pages = {65--108},
title = {{Is Newspaper Coverage of Economic Events Politically Biased?}},
volume = {160},
year = {2014}
}
@article{Malvern2012,
author = {Malvern, David and Richards, Brian},
doi = {10.1002/9781405198431.wbeal0755},
file = {::},
isbn = {9781405198431},
journal = {The Encyclopedia of Applied Linguistics},
number = {2000},
title = {{Measures of Lexical Richness}},
url = {http://doi.wiley.com/10.1002/9781405198431.wbeal0755},
year = {2012}
}
@article{Marshall1977,
annote = {doi: 10.1177/107769907705400127},
author = {Marshall, Hal},
doi = {10.1177/107769907705400127},
file = {::},
issn = {0022-5533},
journal = {Journalism Quarterly},
month = {mar},
number = {1},
pages = {165--169},
publisher = {SAGE Publications},
title = {{Newspaper Accuracy in Tucson}},
url = {https://doi.org/10.1177/107769907705400127},
volume = {54},
year = {1977}
}
@article{McCarthy2010,
abstract = {The main purpose of this study was to examine the validity of the approach to lexical diversity assessment known as the measure of textual lexical diversity (MTLD). The index for this approach is calculated as the mean length of word strings that maintain a criterion level of lexical variation. To validate the MTLD approach, we compared it against the performances of the primary competing indices in the field, which include vocd-D, TTR, Maas, Yule's K, and an HD-D index derived directly from the hypergeometric distribution function. The comparisons involved assessments of convergent validity, divergent validity, internal validity, and incremental validity. The results of our assessments of these indices across two separate corpora suggest three major findings. First, MTLD performs well with respect to all four types of validity and is, in fact, the only index not found to vary as a function of text length. Second, HD-D is a viable alternative to the vocd-D standard. And third, three of the indices--MTLD, vocd-D (or HD-D), and Maas--appear to capture unique lexical information. We conclude by advising researchers to consider using MTLD, vocd-D (or HD-D), and Maas in their studies, rather than any single index, noting that lexical diversity can be assessed in many ways and each approach may be informative as to the construct under investigation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {McCarthy, Philip M. and Jarvis, Scoot},
doi = {10.3758/BRM.42.2.381},
eprint = {arXiv:1011.1669v3},
file = {::},
isbn = {9788578110796},
issn = {1554351X},
journal = {Behavior Research Methods},
number = {2},
pages = {381--392},
pmid = {20479170},
title = {{MTLD, vocd-D, and HD-D: A validation study of sophisticated approaches to lexical diversity assessment}},
volume = {42},
year = {2010}
}
@article{McCarthy2007,
abstract = {A reliable index of lexical diversity (LD) has remained stubbornly elusive for over 60 years. Meanwhile, researchers in fields as varied as stylistics, neuropathology, language acquisition, and even forensics continue to use flawed LD indices ? often ignorant that their results are questionable and in some cases potentially dangerous. Recently, an LD measurement instrument known as vocd has become the virtual tool of the LD trade. In this paper, we report both theoretical and empirical evidence that calls into question the rationale for vocd and also indicates that its reliability is not optimal. Although our evidence shows that vocd's output (D) is a relatively robust indicator of the aggregate probabilities of word occurrences in a text, we show that these probabilities ? and thus also D ? are affected by text length. Malvern, Richards, Chipere and Dur{\'{a}}n (2004) acknowledge that D (as calculated by vocd's default method) can be affected by text length, but claim that the effects are not significant for the ranges of text lengths with which they are concerned. In this paper, we explain why D is affected by text length, and demonstrate with an extensive empirical analysis that the effects of text length are significant over certain ranges, which we identify.},
annote = {doi: 10.1177/0265532207080767},
author = {McCarthy, Philip M and Jarvis, Scott},
doi = {10.1177/0265532207080767},
file = {::},
issn = {0265-5322},
journal = {Language Testing},
month = {oct},
number = {4},
pages = {459--488},
publisher = {SAGE Publications Ltd},
title = {{vocd: A theoretical and empirical evaluation}},
url = {https://doi.org/10.1177/0265532207080767},
volume = {24},
year = {2007}
}
@article{Mcmillan2004,
author = {McMillan, John and Zoido, Pablo},
doi = {10.1257/0895330042632690},
file = {::},
journal = {Journal of Economic Perspectives},
number = {4},
pages = {69--92},
title = {{How to Subvert Democracy: Montesinos in Peru}},
url = {http://www.aeaweb.org/articles?id=10.1257/0895330042632690},
volume = {18},
year = {2004}
}
@article{Miner2015,
abstract = {Can the introduction of the Internet undermine incumbent power in a semi-authoritarian regime? I examine this question using evidence from Malaysia, where the incumbent coalition lost its 40-year monopoly on power in 2008. I develop a novel methodology for measuring Internet penetration, matching IP addresses with physical locations, and apply it to the 2004 to 2008 period in Malaysia. Using distance to the backbone to instrument for endogenous Internet penetration, I find that Internet exposure accounts for 6.6 points, nearly half the swing against the incumbent party in 2008. I find limited evidence of increased turnover, and no evidence of an effect on turnout.},
author = {Miner, Luke},
doi = {10.1016/j.jpubeco.2015.10.002},
file = {::;::},
issn = {0047-2727},
journal = {Journal of Public Economics},
keywords = {Internet diffusion,Malaysian elections,Political economy of the media},
pages = {66--78},
title = {{The Unintended Consequences of Internet Diffusion: Evidence from Malaysia}},
url = {http://www.sciencedirect.com/science/article/pii/S0047272715001802},
volume = {132},
year = {2015}
}
@article{Mullainathan2005,
abstract = {We investigate the market for news under two assumptions: that readers hold beliefs which they like to see confirmed, and that newspapers can slant stories toward these beliefs. We show that, on the topics where readers share common beliefs, one should not expect accuracy even from competitive media: competition results in lower prices, but common slanting toward reader biases. On topics where reader beliefs diverge (such as politically divisive issues), however, newspapers segment the market and slant toward extreme positions. Yet in the aggregate, a reader with access to all news sources could get an unbiased perspective. Generally speaking, reader heterogeneity is more important for accuracy in media than competition per se.},
annote = {Item Citation: The American Economic Review, 9/1/2005, Vol. 95, Issue 4, p. 1031-1053

Accession Number: edsjsr.4132704; Publication Type: Article; Source: The American Economic Review; Language: English; Publication Date: 20050901; Rights: Copyright 1998-2005 American Economic Association; Imprint: American Economic Association},
author = {Mullainathan, Sendhil and Shleifer, Andrei},
doi = {10.1257/0002828054825619},
file = {::},
issn = {00028282},
journal = {The American Economic Review},
keywords = {D23,L82},
number = {4},
pages = {1031},
publisher = {American Economic Association},
title = {{The Market for News}},
url = {http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=edsjsr{\&}AN=edsjsr.4132704{\&}site=eds-live{\&}scope=site},
volume = {95},
year = {2005}
}
@article{Mullainathan2017,
author = {Mullainathan, Sendhil and Spiess, Jann},
doi = {10.1257/jep.31.2.87},
file = {::;::},
journal = {Journal of Economic Perspectives},
number = {2},
pages = {87--106},
title = {{Machine Learning: An Applied Econometric Approach}},
url = {http://www.aeaweb.org/articles?id=10.1257/jep.31.2.87},
volume = {31},
year = {2017}
}
@article{Newman2010,
abstract = {This paper introduces the novel task of topic coherence evaluation, whereby a set of words, as generated by a topic model, is rated for coherence or interpretability. We apply a range of topic scoring models to the evaluation task, drawing on WordNet, Wikipedia and the Google search engine, and existing research on lexical similarity/relatedness. In comparison with human scores for a set of learned topics over two distinct datasets, we show a simple co-occurrence measure based on point- wise mutual information over Wikipedia data is able to achieve results for the task at or nearing the level of inter-annotator correlation, and that other Wikipedia-based lexical relatedness methods also achieve strong results. Google produces strong, if less consistent, results, while our results over WordNet are patchy at best.},
author = {Newman, David and Lau, Jh and Grieser, Karl and Baldwin, Timothy},
file = {::},
isbn = {1932432655},
journal = {Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL},
number = {June},
pages = {100--108},
title = {{Automatic Evaluation of Topic Coherence}},
url = {http://dl.acm.org/citation.cfm?id=1858011},
year = {2010}
}
@article{Newman2010a,
annote = {83513503},
author = {Newman, David and Noh, Youn and Talley, Edmund and Karimi, Sarvnaz and Baldwin, Timothy},
file = {::},
issn = {9781450300858},
journal = {Proceedings of the 10th Annual Joint Conference: Digital Libraries},
month = {jun},
pages = {215},
title = {{Evaluating topic models for digital libraries.}},
url = {http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=edb{\&}AN=83513503{\&}site=eds-live{\&}scope=site},
year = {2010}
}
@article{Oberholzer-Gee2009,
author = {Oberholzer-Gee, Felix and Waldfogel, Joel},
doi = {10.1257/aer.99.5.2120},
file = {::},
journal = {American Economic Review},
number = {5},
pages = {2120--2128},
title = {{Media Markets and Localism: Does Local News en Espa{\~{n}}ol Boost Hispanic Voter Turnout?}},
url = {http://www.aeaweb.org/articles?id=10.1257/aer.99.5.2120},
volume = {99},
year = {2009}
}
@article{Oster2017,
author = {Emily Oster},
title = {Unobservable Selection and Coefficient Stability: Theory and Evidence},
journal = {Journal of Business \& Economic Statistics},
volume = {37},
number = {2},
pages = {187--204},
year = {2019},
publisher = {ASA Website},
doi = {10.1080/07350015.2016.1227711},


URL = { 
    
        https://doi.org/10.1080/07350015.2016.1227711
    
    

},
eprint = { 
    
        https://doi.org/10.1080/07350015.2016.1227711
    
    

}
,
    abstract = { A common approach to evaluating robustness to omitted variable bias is to observe coefficient movements after inclusion of controls. This is informative only if selection on observables is informative about selection on unobservables. Although this link is known in theory in existing literature, very few empirical articles approach this formally. I develop an extension of the theory that connects bias explicitly to coefficient stability. I show that it is necessary to take into account coefficient and R-squared movements. I develop a formal bounding argument. I show two validation exercises and discuss application to the economics literature. Supplementary materials for this article are available online. }
}


@article{Pang2002,
abstract = {We consider the problem of classifying doc- uments not by topic, but by overall senti- ment, e.g., determining whether a review is positive or negative. Using movie re- views as data, we find that standard ma- chine learning techniques definitively out- perform human-produced baselines. How- ever, the three machine learning methods we employed (Naive Bayes, maximum en- tropy classification, and support vector ma- chines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.},
archivePrefix = {arXiv},
arxivId = {cs/0205070},
author = {Pang, Bo and Lee, Lillian and Vaithyanathan, Shivakumar},
doi = {10.3115/1118693.1118704},
eprint = {0205070},
file = {::},
isbn = {9781608458844},
issn = {1554-0669},
journal = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
pages = {79--86},
pmid = {22499159},
primaryClass = {cs},
title = {{Thumbs up?: sentiment classification using machine learning techniques}},
url = {http://portal.acm.org/citation.cfm?id=1118693.1118704},
year = {2002}
}
@article{Pedregosa2012,
abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
archivePrefix = {arXiv},
arxivId = {1201.0490},
author = {Pedregosa, Fabian and Varoquaux, Ga{\"{e}}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Louppe, Gilles and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'{E}}douard},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {1201.0490},
file = {::},
isbn = {1532-4435},
issn = {15324435},
pages = {2825--2830},
pmid = {1000044560},
title = {{Scikit-learn: Machine Learning in Python}},
url = {http://arxiv.org/abs/1201.0490},
volume = {12},
year = {2012}
}
@article{Petrocik1996,
abstract = {This paper develops and applies an issue ownership theory of voting that emphasizes the role of campaigns in setting the criteria for voters to choose between candidates. It expects candidates to emphasize issues on which they are advantaged and their opponents are less well regarded. It explains the structural factors and party system variables which lead candidates to differentially emphasize issues. It invokes theories of priming and framing to explain the electorate's response. Issue emphases are specific to candidates; voters support candidates with a party and performance based reputation for greater competence on handling the issues about which the voter is concerned. Aggregate election outcomes and individual votes follow the problem agenda. Content analysis of news reports, open-ended voter reports of important problems, and the vote are analyzed with graphic displays and logistic regression analysis for presidential elections between 1960 and 1992. Candidates do have distinctive patterns of problem emphases in their campaigns; election outcomes do follow the problem concerns of voters; the individual vote is significantly influenced by these problem concerns above and beyond the effects of the standard predictors.},
author = {Petrocik, John R},
doi = {10.2307/2111797},
issn = {00925853, 15405907},
journal = {American Journal of Political Science},
number = {3},
pages = {825--850},
publisher = {[Midwest Political Science Association, Wiley]},
title = {{Issue Ownership in Presidential Elections, with a 1980 Case Study}},
url = {http://www.jstor.org/stable/2111797},
volume = {40},
year = {1996}
}
@article{Petrova2008,
abstract = {Popular support of redistributive policies depends on information they have about the tax system and efficiency of public projects. Mass media provides a convenient means for manipulating public opinion, even when voters understand that the media can be biased. I develop a theory of media capture in which the rich can influence information published in a media outlet at a cost. The model shows that higher inequality is associated with lower media freedom; this effect is stronger in democratic regimes. I find empirical support for the model in both panel data and cross-country analysis.},
author = {Petrova, Maria},
doi = {10.1016/j.jpubeco.2007.04.004},
file = {::},
issn = {0047-2727},
journal = {Journal of Public Economics},
keywords = {Inequality,Mass media,Public goods,Redistribution},
number = {1},
pages = {183--212},
title = {{Inequality and Media Capture}},
url = {http://www.sciencedirect.com/science/article/pii/S0047272707000606},
volume = {92},
year = {2008}
}
@article{Pritchard2000,
abstract = {We describe a model-based clustering method for using multilocus genotype data to infer population structure and assign individuals to populations. We assume a model in which there are K populations (where K may be unknown), each of which is characterized by a set of allele frequencies at each locus. Individuals in the sample are assigned (probabilistically) to populations, or jointly to two or more populations if their genotypes indicate that they are admixed. Our model does not assume a particular mutation process, and it can be applied to most of the commonly used genetic markers, provided that they are not closely linked. Applications of our method include demonstrating the presence of population structure, assigning individuals to populations, studying hybrid zones, and identifying migrants and admixed individuals. We show that the method can produce highly accurate assignments using modest numbers of loci-e.g. , seven microsatellite loci in an example using genotype data from an endangered bird species. The software used for this article is available from http://www.stats.ox.ac.uk/ approximately pritch/home. html.},
archivePrefix = {arXiv},
arxivId = {gr-qc/0208024},
author = {Pritchard, Jonathan K. and Stephens, Matthew and Donnelly, Peter},
doi = {10.1111/j.1471-8286.2007.01758.x},
eprint = {0208024},
file = {::},
isbn = {0016-6731},
issn = {00166731},
journal = {Genetics},
number = {2},
pages = {945--959},
pmid = {10835412},
primaryClass = {gr-qc},
title = {{Inference of Population Structure Using Multilocus Genotype Data}},
volume = {155},
year = {2000}
}

@article{Puglisi2011,
url = {https://doi.org/10.2202/1935-1682.2025},
title = {Being The New York Times: the Political Behaviour of a Newspaper},
author = {Riccardo Puglisi},
volume = {11},
number = {1},
journal = {The B.E. Journal of Economic Analysis \& Policy},
doi = {10.2202/1935-1682.2025},
year = {2011},
lastchecked = {2024-10-02},
pages = {n/a},
}
@article{Puglisi2011a,
abstract = {We study the coverage of U.S. political scandals by U.S. newspapers during the past decade. Using automatic keyword-based searches we collected data on 32 scandals and approximately 200 newspapers. We find that Democratic-leaning newspapers{\&}{\#}x2014;i.e., those with a higher propensity to endorse Democratic candidates in elections{\&}{\#}x2014;provide relatively more coverage of scandals involving Republican politicians than scandals involving Democratic politicians, while Republican-leaning newspapers tend to do the opposite. This is true even after controlling for the average partisan leanings of readers. In contrast, newspapers appear to cater to the partisan tastes of readers only for local scandals.},
author = {Puglisi, Riccardo and Snyder, James M},
doi = {10.1017/s0022381611000569},
file = {::},
issn = {00223816, 14682508},
journal = {The Journal of Politics},
number = {3},
pages = {931--950},
publisher = {[The University of Chicago Press, Southern Political Science Association]},
title = {{Newspaper Coverage of Political Scandals}},
url = {http://www.jstor.org.ezlibproxy1.ntu.edu.sg/stable/10.1017/s0022381611000569},
volume = {73},
year = {2011}
}
@article{Qian2017,
abstract = {This study provides evidence of government distortion of news coverage among independently owned media outlets in a democratic regime. It uses data from 1946 to 2010 and documents that U.S. news coverage of human rights abuses committed by foreign governments was associated with membership on the United Nations Security Council and the degree of political alliance with the United States. For countries that were not allied with the United States, coverage increased with membership; for countries that are strongly allied with the United States, coverage decreased with membership. There is an analogous effect on reports of human rights abuses by the U.S. State Department, but no such effect on human rights practices according to other measures. The results are driven by the Reagan and Bush Sr. Administrations, 1981–1992, a period during which the government was known to have actively influenced the press. (JEL: P16, N4)},
annote = {10.1093/jeea/jvx007},
author = {Qian, Nancy and Yanagizawa-Drott, David},
issn = {1542-4766},
journal = {Journal of the European Economic Association},
number = {2},
pages = {463--499},
title = {{Government Distortion in Independently Owned Media: Evidence from U.S. News Coverage of Human Rights}},
url = {http://dx.doi.org/10.1093/jeea/jvx007},
volume = {15},
year = {2017}
}
@article{Qin2018,
author = {Qin, Bei and Str{\"{o}}mberg, David and Wu, Yanhui},
file = {::},
journal = {American Economic Review},
number = {9},
pages = {2442--2476},
title = {{Media Bias in China}},
url = {http://www.aeaweb.org/articles?id=10.1257/aer.20170947},
volume = {108},
year = {2018}
}
@article{Qin2017,
author = {Qin, Bei and Str{\"{o}}mberg, David and Wu, Yanhui},
file = {::},
journal = {Journal of Economic Perspectives},
number = {1},
pages = {117--140},
title = {{Why Does China Allow Freer Social Media? Protests versus Surveillance and Propaganda}},
volume = {31},
year = {2017},
doi={10.1257/jep.31.1.117},
}
@inproceedings{Rehurek2010,
author = {Řehůřek, R and Sojka, Petr},
booktitle = {Language Resources and Evaluation Conference},
file = {::},
title = {{Software framework for topic modelling with large corpora}},
url = {http://www.muni.cz/research/publications/884893},
year = {2010}
}
@misc{pfi2017,
author = {{Reporters Without Borders}},
title = {{2017 World Press Freedom Index}},
url = {https://rsf.org/en/ranking/2017},
urldate = {2017-05-30},
year = {2017}
}
@article{Roder2015,
abstract = {Quantifying the coherence of a set of statements is a long standing problem with many potential applications that has attracted researchers from different sciences. The special case of measuring coherence of topics has been recently stud-ied to remedy the problem that topic models give no guar-anty on the interpretablity of their output. Several bench-mark datasets were produced that record human judgements of the interpretability of topics. We are the first to propose a framework that allows to construct existing word based coherence measures as well as new ones by combining ele-mentary components. We conduct a systematic search of the space of coherence measures using all publicly available topic relevance data for the evaluation. Our results show that new combinations of components outperform existing measures with respect to correlation to human ratings. Finally, we outline how our results can be transferred to further appli-cations in the context of text mining, information retrieval and the world wide web.},
author = {R{\"{o}}der, Michael and Both, Andreas and Hinneburg, Alexander},
doi = {10.1145/2684822.2685324},
file = {::},
isbn = {9781450333177},
journal = {Proceedings of the Eighth ACM International Conference on Web Search and Data Mining - WSDM '15},
keywords = {topic coherence,topic evaluation,topic model},
pages = {399--408},
title = {{Exploring the Space of Topic Coherence Measures}},
url = {http://dl.acm.org/citation.cfm?doid=2684822.2685324},
year = {2015}
}
@article{Sievert2014,
abstract = {We present LDAvis, a web-based interactive visualization of topics estimated using Latent Dirichlet Allocation that is built using a combination of R and D3. Our visualization provides a global view of the topics (and how they differ from each other), while at the same time allowing for a deep inspection of the terms most highly associated with each individual topic. First, we propose a novel method for choosing which terms to present to a user to aid in the task of topic interpretation, in which we define the relevance of a term to a topic. Second, we present results from a user study that suggest that ranking terms purely by their probability under a topic is suboptimal for topic interpretation. Last, we describe LDAvis, our visualization system that allows users to flexibly explore topic-term relationships using relevance to better understand a fitted LDA model.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Sievert, Carson and Shirley, Kenneth},
doi = {10.1.1.100.1089},
eprint = {arXiv:1011.1669v3},
file = {::},
isbn = {1932432655},
issn = {10495258},
journal = {Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces},
pages = {63--70},
pmid = {25246403},
title = {{LDAvis: A method for visualizing and interpreting topics}},
url = {http://www.aclweb.org/anthology/W/W14/W14-3110},
year = {2014}
}
@misc{SPHreadership2015,
author = {{Singapore Press Holdings}},
booktitle = {SPH Annual Report},
title = {{Daily Average Newspaper Circulation}},
url = {https://www.sph.com.sg/system/misc/annualreport/2015/SPH{\_}AR2015{\_}DailyAverageNewspaperCirculation.pdf},
year = {2015}
}
@misc{SeditionAct,
author = {{Singapore Statutes Online}},
title = {{Sedition Act}},
url = {http://statutes.agc.gov.sg/aol/search/display/view.w3p;page=0;query=DocId{\%}3A{\%}221f6d9e4b-1cf1-4575-9480-da4bdeff9ef4{\%}22 Status{\%}3Apublished Depth{\%}3A0;rec=0;whole=yes},
year = {1948}
}
@misc{nppa,
author = {{Singapore Statutes Online}},
publisher = {Singapore Statutes Online},
title = {{Newspaper and Printing Presses Act}},
year = {1974}
}
url = {http://statutes.agc.gov.sg/aol/search/display/view.w3p;page=0;query=DocId:{\%}224a71c728-6dbf-4de2-a730-a121b679ffac{\%}22 Status:inforce Depth:0;rec=0;whole=yes{\%}29},
%
@article{Snyder2010a,
abstract = {We estimate the impact of press coverage on citizen knowledge, politicians? actions, and policy. We find that voters living in areas where, for exogenous reasons, the press covers their U.S. House representative less are less likely to recall their representative?s name and less able to describe and rate him or her. Congressmen who are less covered by the local press work less for their constituencies: they are less likely to stand witness before congressional hearings, to serve on constituency?oriented committees (perhaps), and to vote against the party line. Finally, federal spending is lower in areas with exogenously lower press coverage of congressmen.},
annote = {doi: 10.1086/652903},
author = {Snyder, James M. and Str{\"{o}}mberg, David},
doi = {10.1086/652903},
file = {::},
issn = {0022-3808},
journal = {Journal of Political Economy},
number = {2},
pages = {355--408},
publisher = {The University of Chicago Press},
title = {{Press Coverage and Political Accountability}},
url = {https://doi.org/10.1086/652903},
volume = {118},
year = {2010}
}
@article{Stromberg2004,
abstract = {If informed voters receive favorable policies, then the invention of a new mass medium may affect government policies since it affects who is informed and who is not. These ideas are developed in a voting model. The model forms the basis for an empirical investigation of a major New Deal relief program implemented in the middle of the expansion period of radio. The main empirical finding is that U. S. counties with many radio listeners received more relief funds. More funds were allocated to poor counties with high unemployment, but controlling for these and other variables, the effects of radio are large and highly significant. [ABSTRACT FROM AUTHOR] Copyright of Quarterly Journal of Economics is the property of Oxford University Press / USA and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Str{\"{o}}mberg, David 1,2; Affiliations: 1: Institute for International Economic Studies, Stockholm University; 2: CEPR; Issue Info: Feb2004, Vol. 119 Issue 1, p189; Thesaurus Term: RADIO (Medium); Thesaurus Term: PUBLIC spending; Thesaurus Term: MASS media; Thesaurus Term: GOVERNMENT spending policy; Subject Term: VOTING; Subject Term: POLITICAL science; Subject Term: UNITED States -- History -- 1933-1945; NAICS/Industry Codes: 921130 Public Finance Activities; NAICS/Industry Codes: 515111 Radio Networks; Number of Pages: 33p; Illustrations: 2 Diagrams, 5 Charts; Document Type: Article; Full Text Word Count: 12603},
author = {Str{\"{o}}mberg, David},
doi = {10.1162/003355304772839560},
file = {::;::},
isbn = {00335533},
journal = {Quarterly Journal of Economics},
keywords = {GOVERNMENT spending policy,MASS media,POLITICAL science,PUBLIC spending,RADIO (Medium),UNITED States -- History -- 1933-1945,VOTING},
number = {1},
pages = {189--221},
pmid = {12336620},
publisher = {Oxford University Press / USA},
title = {{Radio's Impact on Public Spending}},
url = {http://ezlibproxy1.ntu.edu.sg/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=buh{\&}AN=12336620{\&}site=eds-live{\&}scope=site},
volume = {119},
year = {2004}
}
@article{Sutter2012,
abstract = {Many critics allege that the US national news media is biased in favour of liberal causes and Democratic candidates. The lack of an objective measure of news content ensures that such charges remain controversial. I consider an indirect test for media bias: if the national news media do exhibit a liberal bias, consumption should be higher in liberal media markets, ceteris paribus. I examine determinants of circulation of the three major weekly news magazines across the US and find that Newsweek and Time have higher circulation in liberal markets while US News has higher circulation in conservative markets. The evidence is consistent with a liberal bias for Time and Newsweek, while US News may be relatively conservative (but still left of centre) or absolutely conservative.},
annote = {doi: 10.1080/00036846.2011.577024},
author = {Sutter, Daniel},
doi = {10.1080/00036846.2011.577024},
file = {::},
issn = {0003-6846},
journal = {Applied Economics},
number = {27},
pages = {3521--3532},
publisher = {Routledge},
title = {{Is the Media Liberal? An Indirect Test Using News Magazine Circulation}},
url = {http://dx.doi.org/10.1080/00036846.2011.577024},
volume = {44},
year = {2012}
}
@incollection{Tan2014a,
abstract = {IntroductionThe regime transition literature has found that apart from exogenous shocks, internal splits and leadership succession are the two most likely causes of single-party breakdown. Unlike hegemonic party systems in Mexico and Taiwan that experienced party alternation, Singapore has been governed by one party uninterruptedly for more than five decades. Under the People's Action Party's (PAP) rule, export-oriented Singapore has weathered a series of global financial crises. Even when the country posted a negative growth rate in 2001, the PAP government was able to garner an exceptional 75 percent vote share in the general election (GE) the same year. Now, apart from tackling rising inflation and income inequality, what appears to concern most people is the imminent death of the country's strongman, Lee Kuan Yew. Will the PAP continue to rule and maintain order after the passing of its founding leader?This chapter focuses on the PAP's leadership succession to highlight the key intraparty processes and mechanisms that have kept one of the world's longest-serving political parties together. It argues that the PAP's long-term survival will depend more on institutions than coercion, charisma, or ideological commitment. Indeed, the PAP's incumbency advantage, coupled with an institutionalized leadership succession system, has facilitated self-renewal and kept the party together. Specifically, the elitist leadership selection model, based nominally on meritocracy, is well institutionalized and serves as an incentive distribution system that builds party loyalty and elite cohesion.},
address = {Cambridge},
author = {Tan, Netina},
booktitle = {Party System Institutionalization in Asia: Democracies, Autocracies, and the Shadows of the Past},
doi = {10.1017/CBO9781107300385.003},
editor = {Hicken, Allen and Kuhonta, Erik Martinez},
isbn = {9781107041578},
pages = {49--73},
publisher = {Cambridge University Press},
title = {{Institutionalized Succession and Hegemonic Party Cohesion in Singapore}},
url = {https://www.cambridge.org/core/books/party-system-institutionalization-in-asia/institutionalized-succession-and-hegemonic-party-cohesion-in-singapore/D50A97F11BE99DC3CAC2C28373680090},
year = {2014}
}
@misc{ips2011,
author = {Tan, Tarn How and Chung, Siyoung and Zhang, Weiyu},
file = {::},
publisher = {Institute of Policy Studies},
title = {{Survey on Political Traits and Media Use}},
url = {https://lkyspp.nus.edu.sg/ips/survey-on-political-traits-and-media-use},
year = {2011}
}
@article{Torruella2013,
abstract = {For some time now research has been carried out in the field of lexicometry into the statistical indices that enable lexical richness to be evaluated. The main problem lies in the fact that there should be no influence at all in the results of the formula of the length of the text in terms of the number of words it contains. Therefore, different indices have been designed, which are increasingly complex and sophisticated. This work is a review of the most important indices for calculating lexical richness, in order of complexity, looking into whether or not they are dependent on text length and a comparative analysis of the results of the different indices for different text types is presented.},
author = {Torruella, Joan and Capsada, Ramon},
doi = {10.1016/j.sbspro.2013.10.668},
file = {::},
isbn = {1877-0428},
issn = {18770428},
journal = {Procedia - Social and Behavioral Sciences},
keywords = {lexical richness,lexicometry,text types},
pages = {447--454},
publisher = {Elsevier B.V.},
title = {{Lexical Statistics and Tipological Structures: A Measure of Lexical Richness}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877042813041888},
volume = {95},
year = {2013}
}
@article{Tversky1981,
abstract = {The psychological principles that govern the perception of decision problems and the evaluation of probabilities and outcomes produce predictable shifts of preference when the same problem is framed in different ways. Reversals of preference are demonstrated in choices regarding monetary outcomes, both hypothetical and real, and in questions pertaining to the loss of human lives. The effects of frames on preferences are compared to the effects of perspectives on perceptual appearance. The dependence of preferences on the formulation of decision problems is a significant concern for the theory of rational choice.},
author = {Tversky, A and Kahneman, D},
doi = {10.1126/science.7455683},
file = {::},
journal = {Science},
number = {4481},
pages = {453 -- 458},
title = {{The Framing of Decisions and the Psychology of Choice}},
url = {http://science.sciencemag.org/content/211/4481/453.abstract},
volume = {211},
year = {1981}
}
@article{Varian2014,
author = {Varian, Hal R},
doi = {10.1257/jep.28.2.3},
file = {::;::},
journal = {Journal of Economic Perspectives},
number = {2},
pages = {3--28},
title = {{Big Data: New Tricks for Econometrics}},
url = {http://www.aeaweb.org/articles?id=10.1257/jep.28.2.3},
volume = {28},
year = {2014}
}

@misc{lex,
	author = {Shen, Lucas},
	doi = {10.5281/zenodo.6607007},
	license = {MIT license},
	title = {{LexicalRichness: A small module to compute textual lexical richness}},
	url = {https://github.com/LSYS/lexicalrichness},
	year = {2022}
}

@article{acm,
author = {Morstatter, Fred and Wu, Liang and Yavanoglu, Uraz and Corman, Stephen R. and Liu, Huan},
title = {Identifying Framing Bias in Online News},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
url = {https://doi.org/10.1145/3204948},
doi = {10.1145/3204948},
abstract = {It has been observed that different media outlets exert bias in the way they report the news, which seamlessly influences the way that readers’ knowledge is built through filtering what we read. Therefore, understanding bias in news media is fundamental for obtaining a holistic view of a news story. Traditional work has focused on biases in terms of “agenda setting,” where more attention is allocated to stories that fit their biased narrative. The corresponding method is straightforward, since the bias can be detected through counting the occurrences of different stories/themes within the documents. However, these methods are not applicable to biases which are implicit in wording, namely, “framing” bias. According to framing theory, biased communicators will select and emphasize certain facts and interpretations over others when telling their story. By focusing on facts and interpretations that conform to their bias, they can tell the story in a way that suits their narrative. Automatic detection of framing bias is challenging since nuances in the wording can change the interpretation of the story. In this work, we aim to investigate how the subtle pattern hidden in language use of a news agency can be discovered and further leveraged to detect frames. In particular, we aim to identify the type and polarity of frame in a sentence. Extensive experiments are conducted on real-world data from different countries. A case study is further provided to reveal possible applications of the proposed method.},
journal = {Trans. Soc. Comput.},
month = jun,
articleno = {5},
numpages = {18},
keywords = {Bias, framing, machine learning, natural language processing}
}

@inproceedings{gensim,
address = {Valetta, MT},
author = {Rehurek, Radim and Sojka, Petr},
month = may,
pages = {45--50},
publisher = {University of Malta},
series = {Proceedings of LREC 2010 workshop New Challenges for NLP Frameworks},
title = {{Software Framework for Topic Modelling with Large Corpora}},
url = {http://is.muni.cz/publication/884893/en},
year = {2010},
booktitle = {Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks},
}

@misc{spacy,
author = {Honnibal, Matthew and Montani, Ines and Van Landeghem, Sofie and Boyd, Adriane},
doi = {10.5281/zenodo.1212303},
title = {{spaCy: Industrial-strength Natural Language Processing in Python}},
year = {2020}
}

@misc{v1self,
  Author = {Shen, Lucas},
  Title = {Measuring Political Media Slant Using Text Data},
  url = {https://www.lucasshen.com/research/media.pdf},
  Year = {2021},
}

@article{ErinHengel,
    author = {Hengel, Erin},
    title = "{Publishing While Female: are Women Held to Higher Standards? Evidence from Peer Review}",
    journal = {The Economic Journal},
    volume = {132},
    number = {648},
    pages = {2951-2991},
    year = {2022},
    month = {05},
    abstract = "{Female authors are under-represented in top economics journals. In this paper, I investigate whether higher writing standards contribute to the problem. I find that (i) female-authored papers are 1\%–6\% better written than equivalent papers by men; (ii) the gap widens during peer review; (iii) women improve their writing as they publish more papers (but men do not); (iv) female-authored papers take longer under review. Using a subjective expected utility framework, I argue that higher writing standards for women are consistent with these stylised facts. A counterfactual analysis suggests that senior female economists may, as a result, write at least 5\% more clearly than they otherwise would. As a final exercise, I show tentative evidence that women adapt to biased treatment in ways that may disguise it as voluntary choice.}",
    issn = {0013-0133},
    doi = {10.1093/ej/ueac032},
    url = {https://doi.org/10.1093/ej/ueac032},
    eprint = {https://academic.oup.com/ej/article-pdf/132/648/2951/46859082/ueac032.pdf},
}
@article{fwl_fw,
  author       = {Ragnar Frisch and Frederick V. Waugh},
  title        = {Partial Time Regressions as Compared with Individual Trends},
  journal      = {Econometrica},
  volume       = {1},
  number       = {4},
  year         = {1933},
  pages        = {387--401},
  doi          = {10.2307/1907330},
  publisher    = {The Econometric Society},
  url          = {https://www.jstor.org/stable/1907330}
}
@article{fwl_l,
  author       = {Michael C. Lovell},
  title        = {Seasonal Adjustment of Economic Time Series and Multiple Regression Analysis},
  journal      = {Journal of the American Statistical Association},
  volume       = {58},
  number       = {304},
  year         = {1963},
  pages        = {993--1010},
  doi          = {10.2307/2282963},
  publisher    = {Taylor \& Francis},
  url          = {https://www.jstor.org/stable/2282963}
}


@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@inproceedings{sbert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1908.10084",
    address = "Hong Kong, China",
    pages = "3982--3992",
}

@inproceedings{wolf2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@inproceedings{use,
    title = "Universal Sentence Encoder for {E}nglish",
    author = "Cer, Daniel  and
      Yang, Yinfei  and
      Kong, Sheng-yi  and
      Hua, Nan  and
      Limtiaco, Nicole  and
      St. John, Rhomni  and
      Constant, Noah  and
      Guajardo-Cespedes, Mario  and
      Yuan, Steve  and
      Tar, Chris  and
      Strope, Brian  and
      Kurzweil, Ray",
    editor = "Blanco, Eduardo  and
      Lu, Wei",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-2029",
    doi = "10.18653/v1/D18-2029",
    pages = "169--174",
    abstract = "We present easy-to-use TensorFlow Hub sentence embedding models having good task transfer performance. Model variants allow for trade-offs between accuracy and compute resources. We report the relationship between model complexity, resources, and transfer performance. Comparisons are made with baselines without transfer learning and to baselines that incorporate word-level transfer. Transfer learning using sentence-level embeddings is shown to outperform models without transfer learning and often those that use only word-level transfer. We show good transfer task performance with minimal training data and obtain encouraging results on word embedding association tests (WEAT) of model bias.",
}
@inproceedings{simcse,
    title = "{S}im{CSE}: Simple Contrastive Learning of Sentence Embeddings",
    author = "Gao, Tianyu  and
      Yao, Xingcheng  and
      Chen, Danqi",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.552",
    doi = "10.18653/v1/2021.emnlp-main.552",
    pages = "6894--6910",
    abstract = "This paper presents SimCSE, a simple contrastive learning framework that greatly advances the state-of-the-art sentence embeddings. We first describe an unsupervised approach, which takes an input sentence and predicts itself in a contrastive objective, with only standard dropout used as noise. This simple method works surprisingly well, performing on par with previous supervised counterparts. We find that dropout acts as minimal data augmentation and removing it leads to a representation collapse. Then, we propose a supervised approach, which incorporates annotated pairs from natural language inference datasets into our contrastive learning framework, by using {``}entailment{''} pairs as positives and {``}contradiction{''} pairs as hard negatives. We evaluate SimCSE on standard semantic textual similarity (STS) tasks, and our unsupervised and supervised models using BERT base achieve an average of 76.3{\%} and 81.6{\%} Spearman{'}s correlation respectively, a 4.2{\%} and 2.2{\%} improvement compared to previous best results. We also show{---}both theoretically and empirically{---}that contrastive learning objective regularizes pre-trained embeddings{'} anisotropic space to be more uniform, and it better aligns positive pairs when supervised signals are available.",
}


@incollection{word2vec,
  title={Distributed Representations of Words and Phrases and their Compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S. and Dean, Jeffrey},
  booktitle={Advances in Neural Information Processing Systems},
  editor={Burges, C.J.C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K.Q.},
  volume={26},
  pages={3111--3119},
  year={2013},
  publisher={Curran Associates, Inc.},
  url={https://papers.nips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf},
  address={Lake Tahoe, Nevada, USA},
}
@inproceedings{glove,
  title={GloVe: Global Vectors for Word Representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D.},
  booktitle={Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={1532--1543},
  year={2014},
  publisher={Association for Computational Linguistics},
  doi={10.3115/v1/D14-1162},
  url={https://aclanthology.org/D14-1162},
  address={Doha, Qatar},
}

@inproceedings{bertscore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q. and Artzi, Yoav},
  booktitle={International Conference on Learning Representations},
  year={2020},
  publisher={ICLR Conference Organizers},
  address={Virtual},
  url={https://openreview.net/forum?id=SkeHuCVFDr},
pages = {n/a},
}

@inproceedings{moverscore,
  title={MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance},
  author={Zhao, Wei and Peyrard, Maxime and Liu, Fei and Gao, Yang and Meyer, Christian M. and Eger, Steffen},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},
  pages={563--578},
  year={2019},
  publisher={Association for Computational Linguistics},
  address={Hong Kong, China},
  url={https://aclanthology.org/D19-1053}
}

@article{stm,
author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley, Dustin and Lucas, Christopher and Leder-Luis, Jetson and Gadarian, Shana Kushner and Albertson, Bethany and Rand, David G.},
title = {Structural Topic Models for Open-Ended Survey Responses},
journal = {American Journal of Political Science},
volume = {58},
number = {4},
pages = {1064-1082},
doi = {https://doi.org/10.1111/ajps.12103},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12103},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12103},
abstract = {Collection and especially analysis of open-ended survey responses are relatively rare in the discipline and when conducted are almost exclusively done through human coding. We present an alternative, semiautomated approach, the structural topic model (STM) (Roberts, Stewart, and Airoldi 2013; Roberts et al. 2013), that draws on recent developments in machine learning based analysis of textual data. A crucial contribution of the method is that it incorporates information about the document, such as the author's gender, political affiliation, and treatment assignment (if an experimental study). This article focuses on how the STM is helpful for survey researchers and experimentalists. The STM makes analyzing open-ended responses easier, more revealing, and capable of being used to estimate treatment effects. We illustrate these innovations with analysis of text from surveys and experiments.},
year = {2014}
}
@article{etm,
  title={Topic Modeling in Embedding Spaces},
  author={Dieng, Adji Bousso and Ruiz, Francisco J R and Blei, David M},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={439--453},
  year={2020},
  publisher={MIT Press},
  doi={https://doi.org/10.1162/tacl_a_00325},
}

@misc{bertopic,
  title={BERTopic: Neural topic modeling with a class-based TF-IDF procedure},
  author={Grootendorst, Maarten},
  journal={arXiv preprint arXiv:2203.05794},
  year={2022},
  url={https://arxiv.org/abs/2203.05794},
}
@misc{top2vec,
      title={Top2Vec: Distributed Representations of Topics}, 
      author={Dimo Angelov},
      year={2020},
      eprint={2008.09470},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{stammbach-etal-2023-revisiting,
    title = "Revisiting Automated Topic Model Evaluation with Large Language Models",
    author = "Stammbach, Dominik  and
      Zouhar, Vil{\'e}m  and
      Hoyle, Alexander  and
      Sachan, Mrinmaya  and
      Ash, Elliott",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.581",
    doi = "10.18653/v1/2023.emnlp-main.581",
    pages = "9348--9357",
    abstract = "Topic models help us make sense of large text collections. Automatically evaluating their output and determining the optimal number of topics are both longstanding challenges, with no effective automated solutions to date. This paper proposes using large language models (LLMs) for these tasks. We find that LLMs appropriately assess the resulting topics, correlating more strongly with human judgments than existing automated metrics. However, the setup of the evaluation task is crucial {---} LLMs perform better on coherence ratings of word sets than on intrustion detection. We find that LLMs can also assist us in guiding us towards a reasonable number of topics. In actual applications, topic models are typically used to answer a research question related to a collection of texts. We can incorporate this research question in the prompt to the LLM, which helps estimating the optimal number of topics.",
}
@article{Ash_Poyker,
    author = {Ash, Elliott and Poyker, Michael},
    title = "{Conservative News Media and Criminal Justice: Evidence from Exposure to the Fox News Channel}",
    journal = {The Economic Journal},
    volume = {134},
    number = {660},
    pages = {1331-1355},
    year = {2023},
    month = {12},
    abstract = "{Local exposure to conservative news causes judges to impose harsher criminal sentences. Our evidence comes from an instrumental variable analysis, where randomness in television channel positioning across localities induces exogenous variation in exposure to the Fox News Channel. These treatment data on news viewership are taken to outcome data on almost seven million criminal sentencing decisions in the United States for the years 2005–17. Higher Fox News viewership increases incarceration length, and the effect is stronger for Black defendants and for drug-related crimes. We can rule out changes in the behaviour of police, prosecutors or potential offenders as significant drivers. Consistent with changes in voter attitudes as the key mechanism, the effect on sentencing harshness is observed for elected (but not appointed) judges. Fox News viewership also increases self-reported beliefs about the importance of drug crime as a social problem.}",
    issn = {0013-0133},
    doi = {10.1093/ej/uead108},
    url = {https://doi.org/10.1093/ej/uead108},
}

@misc{contagious,
  author       = {Widmer, Philine and Galletta, Sergio and Ash, Elliott},
  title        = {Media Slant is Contagious},
  journal      = {SSRN Electronic Journal},
  year         = {2023},
  month        = {April},
  doi          = {10.2139/ssrn.3712218},
  url          = {https://ssrn.com/abstract=3712218},
}

@inproceedings{liu2019detecting,
    title = "Detecting Frames in News Headlines and Its Application to Analyzing News Framing Trends Surrounding {U}.{S}. Gun Violence",
    author = "Liu, Siyi  and
      Guo, Lei  and
      Mays, Kate  and
      Betke, Margrit  and
      Wijaya, Derry Tanti",
    editor = "Bansal, Mohit  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/K19-1047/",
    doi = "10.18653/v1/K19-1047",
    pages = "504--514",
    abstract = "Different news articles about the same topic often offer a variety of perspectives: an article written about gun violence might emphasize gun control, while another might promote 2nd Amendment rights, and yet a third might focus on mental health issues. In communication research, these different perspectives are known as ``frames'', which, when used in news media will influence the opinion of their readers in multiple ways. In this paper, we present a method for effectively detecting frames in news headlines. Our training and performance evaluation is based on a new dataset of news headlines related to the issue of gun violence in the United States. This Gun Violence Frame Corpus (GVFC) was curated and annotated by journalism and communication experts. Our proposed approach sets a new state-of-the-art performance for multiclass news frame detection, significantly outperforming a recent baseline by 35.9{\%} absolute difference in accuracy. We apply our frame detection approach in a large scale study of 88k news headlines about the coverage of gun violence in the U.S. between 2016 and 2018."
}


@inproceedings{baly2019multi,
  title={Multi-Task Ordinal Regression for Jointly Predicting the Trustworthiness and the Leading Political Ideology of News Media},
  author={Baly, Ramy and Karadzhov, Georgi and Alexandrov, Dimitar and Glass, James and Nakov, Preslav},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={210--221},
  year={2019},
  doi={10.18653/v1/N19-1216},
  publisher={Association for Computational Linguistics},
  address={Florence, Italy}
}

@inproceedings{tsur2015frame,
  title={A Frame of Mind: Using Statistical Models for Detection of Framing and Agenda Setting Campaigns},
  author={Tsur, Oren and Calacci, Dan and Lazer, David},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={1629--1638},
  year={2015},
  publisher={Association for Computational Linguistics},
  address={Beijing, China},
  doi={10.3115/v1/P15-1157},
}

@inproceedings{yano2010shedding,
  title={Shedding (a Thousand Points of) Light on Biased Language},
  author={Yano, Tae and Resnik, Philip and Smith, Noah A.},
  booktitle={Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon's Mechanical Turk},
  pages={152--158},
  year={2010},
  publisher={Association for Computational Linguistics},
  address={Los Angeles, California, USA},
  url={https://aclanthology.org/W10-0723},
}


@inproceedings{maab-etal-2024-media,
    title = "Media Bias Detection Across Families of Language Models",
    author = "Maab, Iffat  and
      Marrese-Taylor, Edison  and
      Pad{\'o}, Sebastian  and
      Matsuo, Yutaka",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.227",
    doi = "10.18653/v1/2024.naacl-long.227",
    pages = "4083--4098",
    abstract = "Bias in reporting can influence the public{'}s opinion on relevant societal issues. Examples include informational bias (selective presentation of content) and lexical bias (specific framing of content through linguistic choices). The recognition of media bias is arguably an area where NLP can contribute to the {``}social good{''}. Traditional NLP models have shown good performance in classifying media bias, but require careful model design and extensive tuning. In this paper, we ask how well prompting of large language models can recognize media bias. Through an extensive empirical study including a wide selection of pre-trained models, we find that prompt-based techniques can deliver comparable performance to traditional models with greatly reduced effort and that, similar to traditional models, the availability of context substantially improves results. We further show that larger models can leverage different kinds of context simultaneously, obtaining further performance improvements.",
}

@inproceedings{quotus,
  title={QUOTUS: The Structure of Political Media Coverage as Revealed by Quoting Patterns},
  author={Niculae, Vlad and Suen, Caroline and Zhang, Justine and Danescu-Niculescu-Mizil, Cristian and Leskovec, Jure},
  booktitle={Proceedings of the 24th International Conference on World Wide Web},
  pages={798--808},
  year={2015},
  publisher={International World Wide Web Conferences Steering Committee},
  address={Florence, Italy},
  doi={10.1145/2736277.2741688}
}

@article{gentzkow_shapiro_taddy_2019,
    author = {Gentzkow, Matthew and Shapiro, Jesse M. and Taddy, Matt},
    title = {Measuring Group Differences in High-Dimensional Choices: Method and Application to Congressional Speech},
    journal = {Econometrica},
    year = {2019},
    volume = {87},
    number = {4},
    pages = {1307-1340},
    doi = {10.3982/ECTA16566},
    url = {https://onlinelibrary.wiley.com/doi/10.3982/ECTA16566}
}

@inproceedings{sentence-transformers,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1908.10084",
}

@inproceedings{mpnet,
 author = {Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {16857--16867},
 publisher = {Curran Associates, Inc.},
 title = {MPNet: Masked and Permuted Pre-training for Language Understanding},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/c3a690be93aa602ee2dc0ccab5b7b67e-Paper.pdf},
 volume = {33},
 year = {2020}
}
@inproceedings{karpukhin-2stage,
    title = "Dense Passage Retrieval for Open-Domain Question Answering",
    author = "Karpukhin, Vladimir  and
      Oguz, Barlas  and
      Min, Sewon  and
      Lewis, Patrick  and
      Wu, Ledell  and
      Edunov, Sergey  and
      Chen, Danqi  and
      Yih, Wen-tau",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.550/",
    doi = "10.18653/v1/2020.emnlp-main.550",
    pages = "6769--6781",
    abstract = "Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system greatly by 9{\%}-19{\%} absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks."
}
@misc{nogueira-cho,
  author       = {Rodrigo Nogueira and
                  Kyunghyun Cho},
  title        = {Passage Re-ranking with {BERT}},
  journal      = {CoRR},
  volume       = {abs/1901.04085},
  year         = {2019},
  url          = {http://arxiv.org/abs/1901.04085},
  eprinttype    = {arXiv},
  eprint       = {1901.04085},
  timestamp    = {Tue, 25 Feb 2025 13:21:07 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1901-04085.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{msmarco,
    title = "The Curse of Dense Low-Dimensional Information Retrieval for Large Index Sizes",
    author = "Reimers, Nils  and Gurevych, Iryna",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = "8",
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/2012.14210",
    pages = "605--611",
}

@misc{msmarco-data,
      title={MS MARCO: A Human Generated MAchine Reading COmprehension Dataset}, 
      author={Payal Bajaj and Daniel Campos and Nick Craswell and Li Deng and Jianfeng Gao and Xiaodong Liu and Rangan Majumder and Andrew McNamara and Bhaskar Mitra and Tri Nguyen and Mir Rosenberg and Xia Song and Alina Stoica and Saurabh Tiwary and Tong Wang},
      year={2018},
      eprint={1611.09268},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1611.09268}, 
}

@inproceedings{minilLM,
author = {Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
title = {MINILM: deep self-attention distillation for task-agnostic compression of pre-trained transformers},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Pre-trained language models (e.g., BERT [12] and its variants) have achieved remarkable success in varieties of NLP tasks. However, these models usually consist of hundreds of millions of parameters which brings challenges for fine-tuning and online serving in real-life applications due to latency and capacity constraints. In this work, we present a simple and effective approach to compress large Transformer [42] based pre-trained models, termed as deep self-attention distillation. The small model (student) is trained by deeply mimicking the self-attention module, which plays a vital role in Transformer networks, of the large model (teacher). Specifically, we propose distilling the self-attention module of the last Transformer layer of the teacher, which is effective and flexible for the student. Furthermore, we introduce the scaled dot-product between values in the self-attention module as the new deep self-attention knowledge, in addition to the attention distributions (i.e., the scaled dot-product of queries and keys) that have been used in existing works. Moreover, we show that introducing a teacher assistant [26] also helps the distillation of large pre-trained Transformer models. Experimental results demonstrate that our monolingual model outperforms state-of-the-art baselines in different parameter size of student models. In particular, it retains more than 99\% accuracy on SQuAD 2.0 and several GLUE benchmark tasks using 50\% of the Transformer parameters and computations of the teacher model. We also obtain competitive results in applying deep self-attention distillation to multilingual pre-trained models.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {485},
numpages = {13},
location = {Vancouver, BC, Canada},
series = {NIPS '20}
}

@misc{reuters2022singapore,
  author       = {{Edson C. Tandoc Jr}},
  journal       = {{Reuters Institute for the Study of Journalism}},
  title        = {Digital News Report 2022: Singapore},
  year         = {2022},
  month        = jun,
  day          = {15},
  howpublished = {\url{https://reutersinstitute.politics.ox.ac.uk/digital-news-report/2022/singapore}},
}

@InProceedings{dutch_news,
author="Congleton, Christopher
and van der Putten, Peter
and Verberne, Suzan",
editor="Spezzano, Francesca
and Amaral, Adriana
and Ceolin, Davide
and Fazio, Lisa
and Serra, Edoardo",
title="Tracing Political Positioning of Dutch Newspapers",
booktitle="Disinformation in Open Online Media",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="27--43",
abstract="Newspapers write for a particular readership and from a certain ideological or political perspective. This paper applies various natural language processing methods to newspaper articles to analyse to which extent the ideological positioning of newspapers is reflected in their writing. Political bias is illustrated in terms of coverage bias and agenda setting by means of metrics, LDA topic modelling and word embeddings. Furthermore, article source discrimination is analysed by applying various classification models. Finally, the use of generative models (GPT-2) is explored for this purpose. These analyses showed several indications of political tendencies: disproportionate coverage of certain politicians and parties, limited overlap of political discourse, classifiable article source and divergence of generated text thematically and in terms of sentiment. Therefore, reading a newspaper requires a critical attitude which considers the intricate political tendencies of the source.",
isbn="978-3-031-18253-2"
}
@misc{spinde2024,
      title={The Media Bias Taxonomy: A Systematic Literature Review on the Forms and Automated Detection of Media Bias}, 
      author={Timo Spinde and Smi Hinterreiter and Fabian Haak and Terry Ruas and Helge Giese and Norman Meuschke and Bela Gipp},
      year={2024},
      eprint={2312.16148},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.16148}, 
}
@misc{buscemi2024LLM,
      title={Large Language Models' Detection of Political Orientation in Newspapers}, 
      author={Alessio Buscemi and Daniele Proverbio},
      year={2024},
      eprint={2406.00018},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.00018}, 
}

@misc{politicalcompass,
  title        = {The Political Compass},
  author       = {Brittenden, Wayne},
  howpublished = {\url{https://politicalcompass.org}},
  note         = {Online political self-test positioning individuals on two axes: economic (left–right) and social (authoritarian–libertarian). First released December 20, 2000; active as of 2025},
  year         = {2000},
  urldate      = {2025-09-02}
}

@article{MacLaughlin2021, title={Context-Based Quotation Recommendation}, volume={15}, url={https://ojs.aaai.org/index.php/ICWSM/article/view/18070}, DOI={10.1609/icwsm.v15i1.18070}, abstractNote={While composing a new document, anything from a news article to an email or essay, authors often utilize direct quotes from a variety of sources. Although an author may know what point they would like to make, selecting an appropriate quote for the specific context may be time-consuming and difficult. We therefore propose a novel context-aware quote recommendation system which utilizes the content an author has already written to generate a ranked list of quotable paragraphs and spans of tokens from a given source document. We approach quote recommendation as a variant of open-domain question answering and adapt the state-of-the-art BERT-based methods from open-QA to our task. We conduct experiments on a collection of speech transcripts and associated news articles, evaluating models’ paragraph ranking and span prediction performances. Our experiments confirm the strong performance of BERT-based methods on this task, which outperform bag-of-words and neural ranking baselines by more than 30% relative across all ranking metrics. Qualitative analyses show the difficulty of the paragraph and span recommendation tasks and confirm the quotability of the best BERT model’s predictions, even if they are not the true selected quotes from the original news articles.}, number={1}, journal={Proceedings of the International AAAI Conference on Web and Social Media}, author={MacLaughlin, Ansel and Chen, Tao and Ayan, Burcu Karagol and Roth, Dan}, year={2021}, month={May}, pages={397-408} }

@article{Cann2025,
  author    = {Tristan J. B. Cann and Ben Dennes and Travis Coan and Saffron O’Neill and Hywel T. P. Williams},
  title     = {Using semantic similarity to measure the echo of strategic communications},
  journal   = {EPJ Data Science},
  year      = {2025},
  volume    = {14},
  number    = {1},
  pages     = {20},
  doi       = {10.1140/epjds/s13688-025-00538-w},
  url       = {https://doi.org/10.1140/epjds/s13688-025-00538-w},
  issn      = {2193-1127}
}
@article{Lin2025crossencoders,
author = {Lin, Gechun},
title = {Using cross-encoders to measure the similarity of short texts in political science},
journal = {American Journal of Political Science},
volume = {n/a},
number = {n/a},
pages = {},
year = {2025},
doi = {https://doi.org/10.1111/ajps.12956},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12956},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12956},
abstract = {Abstract In many settings, scholars wish to estimate the similarity of political texts. However, the most commonly used methods in political science struggle to identify when two texts convey the same meaning as they rely too heavily on identifying words that appear in both documents. This limitation is especially salient when the underlying documents are short, an increasingly prevalent form of textual data in modern political research. Building on recent advances in computer science, I introduce to political science cross-encoders for precise estimates of semantic similarity in short texts. Scholars can use either off-the-shelf versions or build a customized model. I illustrate this approach in three examples applied to social messages generated in a telephone game, news headlines about US Supreme Court decisions, and Facebook posts from members of Congress. I show that cross-encoders, which utilize pair-level embeddings, offer superior performance across tasks relative to word-based and sentence-level embedding approaches.}
}
@article{vanderGoot2021,
	author = {Emma van der Goot and Toni G.L.A. van der Meer and Rens Vliegenthart},
	title = {Reporting on Political Acquaintances: Personal Interactions Between Political Journalists and Politicians as a Determinant of Media Coverage},
	journal = {International Journal of Communication},
	volume = {15},
	number = {0},
	year = {2021},
	keywords = {media coverage, journalists, politician-journalist contact},
	abstract = {To explain which politicians make it into the news, this study considers the influence of the personal interactions between political journalists and politicians. While theoretically plausible, there is little empirical evidence that the personal interactions between reporters and politicians are associated with news content. This study draws on a survey of political journalists combined with a content analysis of their newspaper articles to analyze how personal interactions with politicians and the background characteristics of journalists relate to their news-making. Overall, it is found that journalists report more often and more positively about politicians they have personal contact with and about those politicians who hold similar political views. Hence, personal interactions with journalists can be useful for politicians to attract (positive) media coverage.},
	issn = {1932-8036},	pages = {23},	url = {https://ijoc.org/index.php/ijoc/article/view/15313}
}

@article{Zhou2020,
author = {Zhou, Yiyi and Ji, Rongrong and Su, Jinsong and Yao, Jiaquan},
title = {Uncovering Media Bias via Social Network Learning},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/3422181},
doi = {10.1145/3422181},
abstract = {It is known that media outlets, such as CNN and FOX, have intrinsic political bias that is reflected in their news reports. The computational prediction of such bias has broad application prospects. However, the prediction is difficult via directly analyzing the news content without high-level context. In contrast, social signals (e.g., the network structure of media followers) provide inspiring cues to uncover such bias. In this article, we realize the first attempt of predicting the latent bias of media outlets by analyzing their social network structures. In particular, we address two key challenges: network sparsity and label sparsity. The network sparsity refers to the partial sampling of the entire follower network in practical analysis and computing, whereas the label sparsity refers to the difficulty of annotating sufficient labels to train the prediction model. To cope with the network sparsity, we propose a hybrid sampling strategy to construct a training corpus that contains network information from micro to macro views. Based on this training corpus, a semi-supervised network embedding approach is proposed to learn low-dimensional yet effective network representations. To deal with the label sparsity, we adopt a graph-based label propagation scheme to supplement the missing links and augment label information for model training. The preceding two steps are iteratively optimized to reinforce each other. We further collect a large-scale dataset containing social networks of 10 media outlets together with about 300,000 followers and more than 5 million connections. Over this dataset, we compare our model to a range of state of the art. Superior performance gains demonstrate the merits of the proposed approach. More importantly, the experimental results and analyses confirm the validity of our approach for the computerized prediction of media bias.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = dec,
articleno = {12},
numpages = {12},
keywords = {Social network embedding, media bias prediction}
}

@article{Guo2022,
author = {Guo, Jiafeng and Cai, Yinqiong and Fan, Yixing and Sun, Fei and Zhang, Ruqing and Cheng, Xueqi},
title = {Semantic Models for the First-Stage Retrieval: A Comprehensive Review},
year = {2022},
issue_date = {October 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/3486250},
doi = {10.1145/3486250},
abstract = {Multi-stage ranking pipelines have been a practical solution in modern search systems, where the first-stage retrieval is to return a subset of candidate documents and latter stages attempt to re-rank those candidates. Unlike re-ranking stages going through quick technique shifts over the past decades, the first-stage retrieval has long been dominated by classical term-based models. Unfortunately, these models suffer from the vocabulary mismatch problem, which may block re-ranking stages from relevant documents at the very beginning. Therefore, it has been a long-term desire to build semantic models for the first-stage retrieval that can achieve high recall efficiently. Recently, we have witnessed an explosive growth of research interests on the first-stage semantic retrieval models. We believe it is the right time to survey current status, learn from existing methods, and gain some insights for future development. In this article, we describe the current landscape of the first-stage retrieval models under a unified framework to clarify the connection between classical term-based retrieval methods, early semantic retrieval methods, and neural semantic retrieval methods. Moreover, we identify some open challenges and envision some future directions, with the hope of inspiring more research on these important yet less investigated topics.},
journal = {ACM Trans. Inf. Syst.},
month = mar,
articleno = {66},
numpages = {42},
keywords = {survey, information retrieval, Semantic retrieval models}
}
